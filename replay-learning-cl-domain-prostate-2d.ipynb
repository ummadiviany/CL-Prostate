{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Continual Learning Pre - Flight Test Methods :  **Replay Learning**","metadata":{}},{"cell_type":"markdown","source":"## Necessary Installs","metadata":{}},{"cell_type":"code","source":"!pip install -q monai einops","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:29.772787Z","iopub.execute_input":"2022-09-10T11:47:29.773410Z","iopub.status.idle":"2022-09-10T11:47:46.359581Z","shell.execute_reply.started":"2022-09-10T11:47:29.773358Z","shell.execute_reply":"2022-09-10T11:47:46.358493Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Necessary Imports","metadata":{}},{"cell_type":"code","source":"# imports and installs\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport nibabel as nib\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\nfrom torch.optim import SGD, Adam, ASGD\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport monai\nfrom monai.transforms import (ScaleIntensityRange, Compose, AddChannel, RandSpatialCrop, ToTensor, \n                            RandAxisFlip, Activations, AsDiscrete, Resize, RandRotate, RandFlip, EnsureType,\n                             KeepLargestConnectedComponent, CenterSpatialCrop)\nfrom monai.metrics import DiceMetric, HausdorffDistanceMetric\nfrom monai.inferers import sliding_window_inference\nfrom monai.losses import DiceLoss, FocalLoss, GeneralizedDiceLoss, DiceCELoss, DiceFocalLoss\nfrom monai.networks.nets import UNet, VNet, UNETR, SwinUNETR, AttentionUnet\nfrom monai.data import decollate_batch, ImageDataset\nfrom monai.utils import set_determinism\nimport os\nimport wandb\nfrom time import time\nfrom einops import rearrange\nfrom einops.layers.torch import Rearrange\nfrom torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingLR\nfrom random import sample\n\ntorch.manual_seed(2000)\nset_determinism(seed=2000)\n\nwandb_log = True","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:46.362337Z","iopub.execute_input":"2022-09-10T11:47:46.362714Z","iopub.status.idle":"2022-09-10T11:47:52.043227Z","shell.execute_reply.started":"2022-09-10T11:47:46.362673Z","shell.execute_reply":"2022-09-10T11:47:52.041552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Create Data Loader ","metadata":{}},{"cell_type":"code","source":"def get_img_label_folds(img_paths, label_paths):\n    \n    fold = list(range(0,len(img_paths)))\n    fold = sample(fold, k=len(fold))\n    fold_imgs = [img_paths[i] for i in fold]\n    fold_labels = [label_paths[i] for i in fold]\n    return fold_imgs, fold_labels\n\n# Transforms for images & labels\ntrain_roi_size = 160\ntransforms_map = {\n        \"train_img_transform\" : [\n            AddChannel(),\n#             CenterSpatialCrop([train_roi_size, train_roi_size, -1]),\n            RandSpatialCrop(roi_size= train_roi_size, random_center = True, random_size=False),\n            ToTensor()\n            ],\n        \"train_label_transform\" : [\n            AddChannel(),\n#             CenterSpatialCrop([train_roi_size, train_roi_size, -1]),\n            RandSpatialCrop(roi_size= train_roi_size, random_center = True, random_size=False),\n            AsDiscrete(threshold=0.5),\n            ToTensor()\n            ],\n        \"test_img_transform\" : [\n            AddChannel(),\n#             CenterSpatialCrop([train_roi_size, train_roi_size, -1]),\n            ToTensor()\n            ],\n        \"test_label_transform\" : [\n            AddChannel(),\n#             CenterSpatialCrop([train_roi_size, train_roi_size, -1]),\n            AsDiscrete(threshold=0.5),\n            ToTensor()\n            ],\n    }\n\n# 1. Image & Label paths\n\ndataset_map = {\n        \"promise12\" : {\n            \"data_dir\" : \"../input/promise12prostatealigned/\",\n            \"test_size\" : 0.1,\n            'test' :  {'images' : [], 'labels' : []},\n            'train' :  {'images' : [], 'labels' : []}\n            \n            },\n        \"decathlon\" : {\n            \"data_dir\" : \"../input/decathlonprostatealigned/\",\n            \"test_size\" : 0.2,\n            'test' :  {'images' : [], 'labels' : []},\n            'train' :  {'images' : [], 'labels' : []}\n            },\n        \"isbi\" : {\n            \"data_dir\" : \"../input/isbiprostatealigned/\",\n            \"test_size\" : 0.2,\n            'test' :  {'images' : [], 'labels' : []},\n            'train' :  {'images' : [], 'labels' : []}\n            }\n    }\n\n\nfor dataset in dataset_map:\n    print(f\"------------{dataset}------------\")\n    data_dir = dataset_map[dataset]['data_dir']\n\n    img_paths = glob(data_dir + \"imagesTr/*.nii\")\n    label_paths = glob(data_dir + \"labelsTr/*.nii\")\n    img_paths.sort()\n    label_paths.sort()\n    \n    # 2. Folds\n\n    images_fold, labels_fold  = get_img_label_folds(img_paths, label_paths)\n    \n    print(\"Number of images: {}\".format(len(images_fold)))\n    print(\"Number of labels: {}\".format(len(labels_fold)))\n    \n    # Get train and test sets\n    # 3. Split into train - test\n    train_idx = int(len(images_fold) * (1 - dataset_map[dataset]['test_size']))\n    \n    # Store train & test sets \n    \n    dataset_map[dataset]['train']['images'] = images_fold[:train_idx]\n    dataset_map[dataset]['train']['labels'] = labels_fold[:train_idx]\n    \n    dataset_map[dataset]['test']['images'] = images_fold[train_idx:]\n    dataset_map[dataset]['test']['labels'] = labels_fold[train_idx:]","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:52.045597Z","iopub.execute_input":"2022-09-10T11:47:52.047344Z","iopub.status.idle":"2022-09-10T11:47:52.199958Z","shell.execute_reply.started":"2022-09-10T11:47:52.047282Z","shell.execute_reply":"2022-09-10T11:47:52.198716Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"------------promise12------------\nNumber of images: 50\nNumber of labels: 50\n------------decathlon------------\nNumber of images: 32\nNumber of labels: 32\n------------isbi------------\nNumber of images: 79\nNumber of labels: 79\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 1\ndef get_dataloader(img_paths : list, label_paths : list, train : bool):\n    \n    if train:\n        ttset = \"train\"\n    else:\n        ttset = \"test\"\n        \n    dataset = ImageDataset(img_paths, label_paths,\n                            transform=Compose(transforms_map[f'{ttset}_img_transform']), \n                            seg_transform=Compose(transforms_map[f'{ttset}_label_transform']))\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    return  dataloader","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:52.202301Z","iopub.execute_input":"2022-09-10T11:47:52.202681Z","iopub.status.idle":"2022-09-10T11:47:52.209299Z","shell.execute_reply.started":"2022-09-10T11:47:52.202648Z","shell.execute_reply":"2022-09-10T11:47:52.208176Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataloaders_map = {}\n\nfor dataset in dataset_map:\n    print(f\"------------{dataset}------------\")\n    for ttset in ['train', 'test']:\n        if ttset == 'train':\n            train = True\n        else:\n            train = False\n        dataloaders_map[dataset] = {}\n        dataloaders_map[dataset]['test'] = get_dataloader(img_paths = dataset_map[dataset][ttset]['images'],\n                                                          label_paths = dataset_map[dataset][ttset]['labels'],\n                                                          train = train)\n        \n        print(f\"\"\"No of samples in {dataset}-{ttset} : {len(dataloaders_map[dataset]['test'])}\"\"\")\n\n# 7. That's it","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:52.210795Z","iopub.execute_input":"2022-09-10T11:47:52.211390Z","iopub.status.idle":"2022-09-10T11:47:52.231904Z","shell.execute_reply.started":"2022-09-10T11:47:52.211356Z","shell.execute_reply":"2022-09-10T11:47:52.231100Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"------------promise12------------\nNo of samples in promise12-train : 45\nNo of samples in promise12-test : 5\n------------decathlon------------\nNo of samples in decathlon-train : 25\nNo of samples in decathlon-test : 7\n------------isbi------------\nNo of samples in isbi-train : 63\nNo of samples in isbi-test : 16\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualize dataset","metadata":{}},{"cell_type":"code","source":"# # ----------------------------Get dataloaders--------------------------\n# imgs,labels = next(iter(dataloaders_map['promise12']['train']))\n# imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n# labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n# print(f\"\\nImage shape : {imgs.shape}\")\n# print(f\"Label shape : {labels.shape}\")\n\n# img_no = 8\n# plt.figure(figsize=(6*3,6*1))\n# plt.subplot(1,3,1)\n# plt.imshow(imgs[img_no,0], cmap='gray')\n# plt.axis('off')\n# plt.title('Image')\n# plt.subplot(1,3,2)\n# plt.imshow(labels[img_no,0], cmap='gray')\n# plt.axis('off')\n# plt.title('Label')\n# plt.subplot(1,3,3)\n# plt.imshow(imgs[img_no,0], cmap='gray')\n# plt.imshow(labels[img_no,0], 'copper', alpha=0.2)\n# plt.axis('off')\n# plt.title('Overlay')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T11:47:52.233561Z","iopub.execute_input":"2022-09-10T11:47:52.234222Z","iopub.status.idle":"2022-09-10T11:47:52.238869Z","shell.execute_reply.started":"2022-09-10T11:47:52.234186Z","shell.execute_reply":"2022-09-10T11:47:52.237777Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Train - Test Statistics","metadata":{}},{"cell_type":"code","source":"# print(f\"\\nTraining samples : {len(train_loader)}\")\n# # print(f\"Testing samples : {len(test_loader)}\")\n\n# # -----------------------Slices-----------------------------\n\n# plt.figure(figsize = (1*7, 1*7))\n\n# slices = [label.shape[4] for _, label in train_loader]\n\n# # plt.subplot(1,2,1)\n# plt.hist(slices, )\n# plt.xlabel('Slices')\n# plt.ylabel('Count')\n# plt.title('Training Set')\n\n# # slices = [label.shape[4] for _, label in test_loader]\n# # plt.subplot(1,2,2)\n# # plt.hist(slices, )\n# # plt.xlabel('Slices')\n# # plt.ylabel('Count')\n# # plt.title('Testing set')\n\n# plt.suptitle('Slices in Training & Testing Sets')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:13:50.845455Z","iopub.execute_input":"2022-09-10T08:13:50.846156Z","iopub.status.idle":"2022-09-10T08:13:50.851630Z","shell.execute_reply.started":"2022-09-10T08:13:50.846117Z","shell.execute_reply":"2022-09-10T08:13:50.850567Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Train Config, Loss, Metrics","metadata":{}},{"cell_type":"code","source":"# ----------------------------Train Config-----------------------------------------\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\nmodel = UNet(\n        spatial_dims=2,\n        in_channels=1,\n        out_channels=2,\n        channels=(16, 32, 64, 128, 256),\n        strides=(2, 2, 2, 2),\n        num_res_units=2,\n    ).to(device)\n\nepochs = 100\ninitial_lr = 1e-3\noptimizer = Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n# optimizer = ASGD(model.parameters(), lr=initial_lr)\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=True)\n# scheduler = ExponentialLR(optimizer, gamma=0.98)\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\nhd_metric = HausdorffDistanceMetric(include_background=False, percentile = 95.)\n\n\n# post_trans = Compose([ToTensor(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\npost_pred = Compose([\n    EnsureType(), AsDiscrete(argmax=True, to_onehot=2),\n    KeepLargestConnectedComponent(applied_labels=[1], is_onehot=True, connectivity=2)\n])\npost_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\nargmax = AsDiscrete(argmax=True)\n# dice_loss = DiceLoss(to_onehot_y=True, softmax=True)\n# bce_loss = nn.BCEWithLogitsLoss()\n# ce_loss = nn.CrossEntropyLoss(weight = torch.tensor([1., 20.], device = device))\n# focal_loss = FocalLoss(to_onehot_y = True, weight = [.5, 95.])\ndice_ce_loss = DiceCELoss(to_onehot_y=True, softmax=True,)\n# dice_focal_loss = DiceFocalLoss(to_onehot_y=True, softmax=True, focal_weight = torch.tensor([1., 5.], device = device))\n# focal_weight = torch.tensor([1., 20.], device = device)\n# weight = torch.tensor([1., 5.], device = device)","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:13:50.853453Z","iopub.execute_input":"2022-09-10T08:13:50.853853Z","iopub.status.idle":"2022-09-10T08:13:53.989436Z","shell.execute_reply.started":"2022-09-10T08:13:50.853817Z","shell.execute_reply":"2022-09-10T08:13:53.988293Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Device: cuda:0\nAdjusting learning rate of group 0 to 1.0000e-03.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## WANDB Logging","metadata":{}},{"cell_type":"code","source":"# ------------------------------------WANDB Logging-------------------------------------\nconfig = {\n    \"Model\" : \"UNet2D\",\n    \"Seqential Strategy\" : \"Replay with 10% dataset buffer storage\",\n    \"Batch Training Strategy\" : \"A batch from current dataset and a batch from episodic memeory are stacked. One backward pass and paramenter update.\",\n    \"Train Input ROI size\" : train_roi_size,\n#     \"Test Input size\" : (1, 320, 320),\n    \"Test mode\" : f\"Sliding window inference roi = {train_roi_size}\",\n    \"Batch size\" : \"No of slices in original volume\",\n    \"No of volumes per batch\" : 1,\n    \"Epochs\" : epochs,\n    \"Optimizer\" : \"Adam\",\n    \"Scheduler\" : \"CosineAnnealingLR\",\n    \"Initial LR\" : scheduler.get_last_lr()[0],\n    \"Loss\" : \"DiceCELoss\", \n    \"Train Data Augumentations\" : \"RandSpatialCrop\",\n    \"Test Data Preprocess\" : \"None\",\n    \"Train samples\" : {\"Promise12\" : 45, \"ISBI\" : 63, \"Decathlon\" : 25},\n    \"Test Samples\" : {\"Promise12\" : 5, \"ISBI\" : 16, \"Decathlon\" : 7},\n#     RandFlip, RandRotate90, RandGaussianNoise, RandGaussSmooth, RandBiasField, RandContrast\n    \"Pred Post Processing\" : \"KeepLargestConnectedComponent\"\n}\nif wandb_log:\n    wandb.login()\n    wandb.init(project=\"CL_Sequential\", entity=\"vinayu\", config = config)","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:13:53.991304Z","iopub.execute_input":"2022-09-10T08:13:53.991685Z","iopub.status.idle":"2022-09-10T08:18:42.095319Z","shell.execute_reply.started":"2022-09-10T08:13:53.991647Z","shell.execute_reply":"2022-09-10T08:18:42.094345Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinayu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220910_081835-3vqbi6yd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/vinayu/CL_Sequential/runs/3vqbi6yd\" target=\"_blank\">devoted-donkey-10</a></strong> to <a href=\"https://wandb.ai/vinayu/CL_Sequential\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Replay Training","metadata":{}},{"cell_type":"markdown","source":"## Training function ","metadata":{}},{"cell_type":"code","source":"# def batch_train(batch_imgs : torch.Tensor, batch_labels : torch.Tensor):\n    \n    \n#     imgs = batch_imgs.to(device)\n#     labels = batch_labels.to(device)\n#     imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n#     labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n#     preds = model(imgs)\n\n#     loss = dice_ce_loss(preds, labels)\n\n#     preds = [post_pred(i) for i in decollate_batch(preds)]\n#     preds = torch.stack(preds)\n#     labels = [post_label(i) for i in decollate_batch(labels)]\n#     labels = torch.stack(labels)\n    \n#     # Metric scores\n#     dice_metric(preds, labels)\n#     hd_metric(preds, labels)\n\n#     return loss","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.099809Z","iopub.execute_input":"2022-09-10T08:18:42.100382Z","iopub.status.idle":"2022-09-10T08:18:42.106584Z","shell.execute_reply.started":"2022-09-10T08:18:42.100339Z","shell.execute_reply":"2022-09-10T08:18:42.105593Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Serial Batch Training ","metadata":{}},{"cell_type":"code","source":"# def train(train_loader : DataLoader, em_loader : DataLoader):\n#     \"\"\"\n#     Inputs : No Inputs\n#     Outputs : No Outputs\n#     Function : Trains all samples in train_loader and log metrics to WANDB\n#     \"\"\"\n    \n#     train_start = time()\n#     epoch_loss = 0\n#     model.train()\n#     print('\\n')\n    \n    \n#     # Iterating over the dataset\n#     for i, (imgs, labels) in enumerate(train_loader, 1):\n        \n        \n#         # Set all grads to zero before any training\n        \n#         optimizer.zero_grad()\n        \n#         # Get a single batch(imgs, labels) from train loader and call train_batch on it\n        \n#         loss = batch_train(batch_imgs = imgs, batch_labesl = labels)\n        \n#         # Get a single random batch(imgs, labels) from em_loader and call train_batch on it\n        \n#         loss += batch_train(batch_imgs = imgs, batch_labesl = labels)\n        \n#         # Accumulate the loss from both batches\n        \n#         # Compute loss with backward pass\n        \n#         # Optimize the parameters\n        \n#         # \n\n        \n#         preds = model(imgs)\n\n#         loss = dice_ce_loss(preds, labels)\n\n#         preds = [post_pred(i) for i in decollate_batch(preds)]\n#         preds = torch.stack(preds)\n#         labels = [post_label(i) for i in decollate_batch(labels)]\n#         labels = torch.stack(labels)\n#     #         Metric scores\n#         dice_metric(preds, labels)\n#         hd_metric(preds, labels)\n\n#         loss.backward()\n#         optimizer.step()\n\n#         epoch_loss += loss.item()\n\n#         if i % batch_interval == 0:\n#             print(f\"Epoch: [{epoch}/{epochs}], Batch: [{i}/{len(train_loader)}], Loss: {loss.item() :.4f}, \\\n#                   Dice: {dice_metric.aggregate().item() * 100 :.2f}, HD: {hd_metric.aggregate().item() :.2f}\")\n    \n#     # Print metrics, log data, reset metrics\n    \n#     print(f\"\\nEpoch: [{epoch}/{epochs}], Avg Loss: {epoch_loss / len(train_loader) :.3f}, \\\n#               Train Dice: {dice_metric.aggregate().item() * 100 :.2f}, Train HD: {hd_metric.aggregate().item() :.2f}, Time : {int(time() - train_start)} sec\")\n\n# #     if wandb_log:\n# #         wandb.log({\"Train Dice\" : dice_metric.aggregate().item() * 100,\n# #                    \"Train Hausdorff Distance\" : hd_metric.aggregate().item(),\n# #                    \"Train Loss\" : epoch_loss / len(train_loader),\n# #                    \"Learning Rate\" : scheduler.get_last_lr()[0],\n# #                    \"Epoch\" : epoch })\n\n\n#     dice_metric.reset()\n#     hd_metric.reset()\n#     scheduler.step()\n","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.111353Z","iopub.execute_input":"2022-09-10T08:18:42.113050Z","iopub.status.idle":"2022-09-10T08:18:42.123570Z","shell.execute_reply.started":"2022-09-10T08:18:42.113007Z","shell.execute_reply":"2022-09-10T08:18:42.122696Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Stacked Batch Training","metadata":{}},{"cell_type":"code","source":"def train(train_loader : DataLoader, em_loader : DataLoader = None):\n    \"\"\"\n    Inputs : No Inputs\n    Outputs : No Outputs\n    Function : Trains all datasets and logs metrics to WANDB\n    \"\"\"\n    \n    train_start = time()\n    epoch_loss = 0\n    model.train()\n    print('\\n')\n    \n    \n    # Iterating over the dataset\n    for i, (imgs, labels) in enumerate(train_loader, 1):\n\n        imgs, labels = imgs.to(device), labels.to(device)\n        \n        if em_loader is not None:\n            em_imgs, em_labels = next(iter(em_loader))\n            em_imgs, em_labels = em_imgs.to(device), em_labels.to(device)\n        \n            # Stacking up batch from current dataset and episodic memeory \n            imgs, labels = torch.cat([imgs, em_imgs], dim=-1), torch.cat([labels, em_labels], dim=-1)\n        \n        imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n        labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n        optimizer.zero_grad()\n        preds = model(imgs)\n\n        loss = dice_ce_loss(preds, labels)\n\n        preds = [post_pred(i) for i in decollate_batch(preds)]\n        preds = torch.stack(preds)\n        labels = [post_label(i) for i in decollate_batch(labels)]\n        labels = torch.stack(labels)\n    #         Metric scores\n        dice_metric(preds, labels)\n        hd_metric(preds, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n        if i % batch_interval == 0:\n            print(f\"Epoch: [{epoch}/{epochs}], Batch: [{i}/{len(train_loader)}], Loss: {loss.item() :.4f}, \\\n                  Dice: {dice_metric.aggregate().item() * 100 :.2f}, HD: {hd_metric.aggregate().item() :.2f}\")\n    \n    # Print metrics, log data, reset metrics\n    \n    print(f\"\\nEpoch: [{epoch}/{epochs}], Avg Loss: {epoch_loss / len(train_loader) :.3f}, \\\n              Train Dice: {dice_metric.aggregate().item() * 100 :.2f}, Train HD: {hd_metric.aggregate().item() :.2f}, Time : {int(time() - train_start)} sec\")\n\n#     if wandb_log:\n#         wandb.log({\"Train Dice\" : dice_metric.aggregate().item() * 100,\n#                    \"Train Hausdorff Distance\" : hd_metric.aggregate().item(),\n#                    \"Train Loss\" : epoch_loss / len(train_loader),\n#                    \"Learning Rate\" : scheduler.get_last_lr()[0],\n#                    \"Epoch\" : epoch })\n\n\n    dice_metric.reset()\n    hd_metric.reset()\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.128514Z","iopub.execute_input":"2022-09-10T08:18:42.128851Z","iopub.status.idle":"2022-09-10T08:18:42.147451Z","shell.execute_reply.started":"2022-09-10T08:18:42.128819Z","shell.execute_reply":"2022-09-10T08:18:42.146530Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Validation function","metadata":{}},{"cell_type":"code","source":"batch_size = 1\ntest_shuffle = True\n\ntest_map_config = {\n            'promise12' : {'roi_size' : 160},\n            'isbi' : {'roi_size' : 160},\n            'decathlon' : {'roi_size' : 160},\n           }\n","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.149003Z","iopub.execute_input":"2022-09-10T08:18:42.149712Z","iopub.status.idle":"2022-09-10T08:18:42.166014Z","shell.execute_reply.started":"2022-09-10T08:18:42.149677Z","shell.execute_reply":"2022-09-10T08:18:42.165016Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def validate(test_loader : DataLoader, dataset_name : str = None):\n    \"\"\"\n    Inputs : Testing dataloader\n    Outputs : Returns Dice, HD\n    Function : Validate on the given dataloader and return the mertics \n    \"\"\"\n    train_start = time()\n    model.eval()\n    with torch.no_grad():\n        # Iterate over all samples in the dataset\n        for i, (imgs, labels) in enumerate(test_loader, 1):\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n            imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n            labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n            roi_size = (test_map_config[dataset_name]['roi_size'], test_map_config[dataset_name]['roi_size'])\n            preds = sliding_window_inference(inputs=imgs, roi_size=roi_size, sw_batch_size=4,\n                                            predictor=model, overlap = 0.5, mode = 'gaussian', device=device)\n#                 preds = model(imgs)\n            preds = [post_pred(i) for i in decollate_batch(preds)]\n            preds = torch.stack(preds)\n            labels = [post_label(i) for i in decollate_batch(labels)]\n            labels = torch.stack(labels)\n\n            dice_metric(preds, labels)\n            hd_metric(preds, labels)\n\n        val_dice = dice_metric.aggregate().item()\n        val_hd = hd_metric.aggregate().item()\n        \n        dice_metric.reset()\n        hd_metric.reset()\n        \n        print(\"-\"*75)\n        print(f\"Epoch : [{epoch}/{epochs}], Dataset : {dataset_name.upper()}, Test Avg Dice : {val_dice*100 :.2f}, Test Avg HD : {val_hd :.2f}, Time : {int(time() - train_start)} sec\")\n        print(\"-\"*75)\n        \n        return val_dice, val_hd","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.167650Z","iopub.execute_input":"2022-09-10T08:18:42.167978Z","iopub.status.idle":"2022-09-10T08:18:42.181938Z","shell.execute_reply.started":"2022-09-10T08:18:42.167946Z","shell.execute_reply":"2022-09-10T08:18:42.180981Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Trainer & Validator","metadata":{}},{"cell_type":"code","source":"val_interval = 5\nbatch_interval = 25","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.183448Z","iopub.execute_input":"2022-09-10T08:18:42.184313Z","iopub.status.idle":"2022-09-10T08:18:42.193904Z","shell.execute_reply.started":"2022-09-10T08:18:42.184129Z","shell.execute_reply":"2022-09-10T08:18:42.192996Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Main Training Sequence","metadata":{}},{"cell_type":"markdown","source":"### Initialize replay memory buffer ","metadata":{}},{"cell_type":"code","source":"# Empty replay buffer as a list\nreplay_buffer = {\n    \"train\" : {\n        'images' : [],\n        'labels' : [],\n    },\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.195407Z","iopub.execute_input":"2022-09-10T08:18:42.196529Z","iopub.status.idle":"2022-09-10T08:18:42.204004Z","shell.execute_reply.started":"2022-09-10T08:18:42.196493Z","shell.execute_reply":"2022-09-10T08:18:42.202959Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Training on Promise12 --> Testing on Promise12\nepochs = 100\ninitial_lr = 1e-3\noptimizer = Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n# optimizer = ASGD(model.parameters(), lr=initial_lr)\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=True)\n\ndataset_name = 'promise12'\ntrain_loader = get_dataloader(img_paths = dataset_map[dataset_name]['train']['images'],\n                              label_paths = dataset_map[dataset_name]['train']['labels'],\n                              train = True)\n\ntest_dataset_names = ['promise12']\n\nmetric_prefix  = 'p12->'\n\nmetrics_map = {}\nfor dname in test_dataset_names:\n    metrics_map[dname] = {\n        f'{metric_prefix}_{dname}_curr_dice' : 0,\n        f'{metric_prefix}_{dname}_best_dice' : 0,\n        f'{metric_prefix}_{dname}_curr_hd' : 1e10,\n        f'{metric_prefix}_{dname}_best_hd' : 1e10,\n        'Epoch' : 0\n    }\n\nfor epoch in range(1, epochs+1):   \n    \n        train(train_loader = train_loader, em_loader = None)\n        \n        if epoch % val_interval == 0:\n            for dname in test_dataset_names:\n                val_dice, val_hd = validate(test_loader = dataloaders_map[dname]['test'], dataset_name = dname)\n\n                val_dice *= 100\n\n                metrics = metrics_map[dname]\n\n                metrics[f'Epoch'] = epoch\n                metrics[f'{metric_prefix}_{dname}_curr_dice'] = val_dice \n                metrics[f'{metric_prefix}_{dname}_curr_hd'] = val_hd\n                metrics[f'{metric_prefix}_{dname}_best_dice'] = max(val_dice, metrics[f'{metric_prefix}_{dname}_best_dice'])\n\n                if val_hd < metrics[f'{metric_prefix}_{dname}_best_hd'] and val_hd > 0:\n                    metrics[f'{metric_prefix}_{dname}_best_hd'] = val_hd\n\n                if wandb_log:\n                    # Quantiative metrics\n                    wandb.log(metrics)\n                    print('Logged data to wandb')","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:18:42.207236Z","iopub.execute_input":"2022-09-10T08:18:42.208376Z","iopub.status.idle":"2022-09-10T08:40:36.710713Z","shell.execute_reply.started":"2022-09-10T08:18:42.208338Z","shell.execute_reply":"2022-09-10T08:40:36.709447Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/monai/metrics/hausdorff_distance.py:168: UserWarning: the ground truth of class 0 is all 0, this may result in nan/inf distance.\n  warnings.warn(f\"the ground truth of class {c} is all 0, this may result in nan/inf distance.\")\n/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py:4009: RuntimeWarning: invalid value encountered in subtract\n  diff_b_a = subtract(b, a)\n","output_type":"stream"},{"name":"stdout","text":"Epoch: [1/100], Batch: [25/45], Loss: 0.9604,                   Dice: 0.52, HD: 92.55\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/monai/metrics/hausdorff_distance.py:170: UserWarning: the prediction of class 0 is all 0, this may result in nan/inf distance.\n  warnings.warn(f\"the prediction of class {c} is all 0, this may result in nan/inf distance.\")\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: [1/100], Avg Loss: 1.004,               Train Dice: 0.29, Train HD: 97.66, Time : 43 sec\nAdjusting learning rate of group 0 to 9.9975e-04.\n\n\nEpoch: [2/100], Batch: [25/45], Loss: 0.8095,                   Dice: 2.00, HD: 82.41\n\nEpoch: [2/100], Avg Loss: 0.836,               Train Dice: 2.37, Train HD: 84.36, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9901e-04.\n\n\nEpoch: [3/100], Batch: [25/45], Loss: 0.7148,                   Dice: 0.07, HD: 80.41\n\nEpoch: [3/100], Avg Loss: 0.749,               Train Dice: 1.42, Train HD: 75.16, Time : 11 sec\nAdjusting learning rate of group 0 to 9.9778e-04.\n\n\nEpoch: [4/100], Batch: [25/45], Loss: 0.6459,                   Dice: 0.13, HD: 61.66\n\nEpoch: [4/100], Avg Loss: 0.695,               Train Dice: 3.13, Train HD: 63.75, Time : 11 sec\nAdjusting learning rate of group 0 to 9.9606e-04.\n\n\nEpoch: [5/100], Batch: [25/45], Loss: 0.9526,                   Dice: 0.00, HD: 104.31\n\nEpoch: [5/100], Avg Loss: 0.679,               Train Dice: 0.40, Train HD: 84.76, Time : 11 sec\nAdjusting learning rate of group 0 to 9.9384e-04.\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : PROMISE12, Test Avg Dice : 7.29, Test Avg HD : 123.85, Time : 7 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [6/100], Batch: [25/45], Loss: 0.6261,                   Dice: 3.86, HD: 80.28\n\nEpoch: [6/100], Avg Loss: 0.670,               Train Dice: 2.32, Train HD: 80.99, Time : 11 sec\nAdjusting learning rate of group 0 to 9.9114e-04.\n\n\nEpoch: [7/100], Batch: [25/45], Loss: 0.5896,                   Dice: 1.30, HD: 83.13\n\nEpoch: [7/100], Avg Loss: 0.668,               Train Dice: 0.88, Train HD: 78.08, Time : 11 sec\nAdjusting learning rate of group 0 to 9.8796e-04.\n\n\nEpoch: [8/100], Batch: [25/45], Loss: 0.6122,                   Dice: 4.15, HD: 84.89\n\nEpoch: [8/100], Avg Loss: 0.660,               Train Dice: 2.11, Train HD: 80.90, Time : 11 sec\nAdjusting learning rate of group 0 to 9.8429e-04.\n\n\nEpoch: [9/100], Batch: [25/45], Loss: 0.5803,                   Dice: 0.04, HD: 54.45\n\nEpoch: [9/100], Avg Loss: 0.634,               Train Dice: 0.03, Train HD: 60.12, Time : 10 sec\nAdjusting learning rate of group 0 to 9.8015e-04.\n\n\nEpoch: [10/100], Batch: [25/45], Loss: 0.5803,                   Dice: 2.76, HD: 50.46\n\nEpoch: [10/100], Avg Loss: 0.612,               Train Dice: 1.64, Train HD: 53.30, Time : 10 sec\nAdjusting learning rate of group 0 to 9.7553e-04.\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : PROMISE12, Test Avg Dice : 0.00, Test Avg HD : 0.00, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [11/100], Batch: [25/45], Loss: 0.9529,                   Dice: 3.10, HD: 66.41\n\nEpoch: [11/100], Avg Loss: 0.647,               Train Dice: 3.91, Train HD: 61.94, Time : 11 sec\nAdjusting learning rate of group 0 to 9.7044e-04.\n\n\nEpoch: [12/100], Batch: [25/45], Loss: 0.5223,                   Dice: 1.52, HD: 66.85\n\nEpoch: [12/100], Avg Loss: 0.659,               Train Dice: 0.99, Train HD: 64.09, Time : 11 sec\nAdjusting learning rate of group 0 to 9.6489e-04.\n\n\nEpoch: [13/100], Batch: [25/45], Loss: 0.6261,                   Dice: 3.05, HD: 60.55\n\nEpoch: [13/100], Avg Loss: 0.634,               Train Dice: 1.95, Train HD: 61.58, Time : 11 sec\nAdjusting learning rate of group 0 to 9.5888e-04.\n\n\nEpoch: [14/100], Batch: [25/45], Loss: 0.5967,                   Dice: 0.36, HD: 71.12\n\nEpoch: [14/100], Avg Loss: 0.625,               Train Dice: 0.34, Train HD: 66.21, Time : 10 sec\nAdjusting learning rate of group 0 to 9.5241e-04.\n\n\nEpoch: [15/100], Batch: [25/45], Loss: 0.6020,                   Dice: 9.68, HD: 54.46\n\nEpoch: [15/100], Avg Loss: 0.668,               Train Dice: 6.74, Train HD: 62.63, Time : 11 sec\nAdjusting learning rate of group 0 to 9.4550e-04.\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : PROMISE12, Test Avg Dice : 9.41, Test Avg HD : 117.26, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [16/100], Batch: [25/45], Loss: 0.5622,                   Dice: 10.10, HD: 61.49\n\nEpoch: [16/100], Avg Loss: 0.608,               Train Dice: 10.19, Train HD: 64.56, Time : 11 sec\nAdjusting learning rate of group 0 to 9.3815e-04.\n\n\nEpoch: [17/100], Batch: [25/45], Loss: 0.5354,                   Dice: 30.93, HD: 49.53\n\nEpoch: [17/100], Avg Loss: 0.614,               Train Dice: 34.04, Train HD: 48.36, Time : 12 sec\nAdjusting learning rate of group 0 to 9.3037e-04.\n\n\nEpoch: [18/100], Batch: [25/45], Loss: 0.6054,                   Dice: 22.64, HD: 52.38\n\nEpoch: [18/100], Avg Loss: 0.614,               Train Dice: 28.58, Train HD: 52.49, Time : 12 sec\nAdjusting learning rate of group 0 to 9.2216e-04.\n\n\nEpoch: [19/100], Batch: [25/45], Loss: 0.5641,                   Dice: 48.51, HD: 28.71\n\nEpoch: [19/100], Avg Loss: 0.598,               Train Dice: 41.29, Train HD: 36.72, Time : 12 sec\nAdjusting learning rate of group 0 to 9.1354e-04.\n\n\nEpoch: [20/100], Batch: [25/45], Loss: 0.5351,                   Dice: 37.27, HD: 48.15\n\nEpoch: [20/100], Avg Loss: 0.584,               Train Dice: 40.36, Train HD: 42.22, Time : 12 sec\nAdjusting learning rate of group 0 to 9.0451e-04.\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : PROMISE12, Test Avg Dice : 66.16, Test Avg HD : 39.79, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [21/100], Batch: [25/45], Loss: 0.4953,                   Dice: 43.25, HD: 43.25\n\nEpoch: [21/100], Avg Loss: 0.561,               Train Dice: 42.37, Train HD: 40.93, Time : 12 sec\nAdjusting learning rate of group 0 to 8.9508e-04.\n\n\nEpoch: [22/100], Batch: [25/45], Loss: 0.6485,                   Dice: 35.55, HD: 47.14\n\nEpoch: [22/100], Avg Loss: 0.573,               Train Dice: 43.82, Train HD: 42.02, Time : 11 sec\nAdjusting learning rate of group 0 to 8.8526e-04.\n\n\nEpoch: [23/100], Batch: [25/45], Loss: 0.4267,                   Dice: 44.59, HD: 41.43\n\nEpoch: [23/100], Avg Loss: 0.560,               Train Dice: 42.23, Train HD: 42.65, Time : 12 sec\nAdjusting learning rate of group 0 to 8.7506e-04.\n\n\nEpoch: [24/100], Batch: [25/45], Loss: 0.6051,                   Dice: 49.43, HD: 34.10\n\nEpoch: [24/100], Avg Loss: 0.588,               Train Dice: 46.57, Train HD: 39.93, Time : 12 sec\nAdjusting learning rate of group 0 to 8.6448e-04.\n\n\nEpoch: [25/100], Batch: [25/45], Loss: 0.6114,                   Dice: 52.20, HD: 31.97\n\nEpoch: [25/100], Avg Loss: 0.574,               Train Dice: 43.49, Train HD: 41.43, Time : 12 sec\nAdjusting learning rate of group 0 to 8.5355e-04.\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : PROMISE12, Test Avg Dice : 57.32, Test Avg HD : 39.19, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [26/100], Batch: [25/45], Loss: 0.5756,                   Dice: 42.92, HD: 40.79\n\nEpoch: [26/100], Avg Loss: 0.529,               Train Dice: 52.79, Train HD: 33.87, Time : 11 sec\nAdjusting learning rate of group 0 to 8.4227e-04.\n\n\nEpoch: [27/100], Batch: [25/45], Loss: 0.5776,                   Dice: 56.20, HD: 30.12\n\nEpoch: [27/100], Avg Loss: 0.537,               Train Dice: 46.22, Train HD: 37.38, Time : 12 sec\nAdjusting learning rate of group 0 to 8.3066e-04.\n\n\nEpoch: [28/100], Batch: [25/45], Loss: 0.4490,                   Dice: 54.56, HD: 35.86\n\nEpoch: [28/100], Avg Loss: 0.564,               Train Dice: 49.40, Train HD: 37.88, Time : 11 sec\nAdjusting learning rate of group 0 to 8.1871e-04.\n\n\nEpoch: [29/100], Batch: [25/45], Loss: 0.4072,                   Dice: 53.89, HD: 34.73\n\nEpoch: [29/100], Avg Loss: 0.536,               Train Dice: 51.87, Train HD: 37.08, Time : 11 sec\nAdjusting learning rate of group 0 to 8.0645e-04.\n\n\nEpoch: [30/100], Batch: [25/45], Loss: 0.5875,                   Dice: 49.73, HD: 37.99\n\nEpoch: [30/100], Avg Loss: 0.535,               Train Dice: 52.79, Train HD: 33.44, Time : 12 sec\nAdjusting learning rate of group 0 to 7.9389e-04.\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : PROMISE12, Test Avg Dice : 70.32, Test Avg HD : 25.89, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [31/100], Batch: [25/45], Loss: 0.3004,                   Dice: 51.90, HD: 37.61\n\nEpoch: [31/100], Avg Loss: 0.540,               Train Dice: 52.39, Train HD: 35.60, Time : 11 sec\nAdjusting learning rate of group 0 to 7.8104e-04.\n\n\nEpoch: [32/100], Batch: [25/45], Loss: 0.4003,                   Dice: 50.07, HD: 38.95\n\nEpoch: [32/100], Avg Loss: 0.497,               Train Dice: 50.38, Train HD: 36.75, Time : 11 sec\nAdjusting learning rate of group 0 to 7.6791e-04.\n\n\nEpoch: [33/100], Batch: [25/45], Loss: 0.4896,                   Dice: 66.60, HD: 20.35\n\nEpoch: [33/100], Avg Loss: 0.519,               Train Dice: 56.89, Train HD: 29.96, Time : 11 sec\nAdjusting learning rate of group 0 to 7.5452e-04.\n\n\nEpoch: [34/100], Batch: [25/45], Loss: 0.5106,                   Dice: 47.85, HD: 37.89\n\nEpoch: [34/100], Avg Loss: 0.486,               Train Dice: 51.36, Train HD: 33.51, Time : 11 sec\nAdjusting learning rate of group 0 to 7.4088e-04.\n\n\nEpoch: [35/100], Batch: [25/45], Loss: 0.5199,                   Dice: 61.28, HD: 28.11\n\nEpoch: [35/100], Avg Loss: 0.498,               Train Dice: 56.60, Train HD: 31.91, Time : 12 sec\nAdjusting learning rate of group 0 to 7.2700e-04.\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : PROMISE12, Test Avg Dice : 63.10, Test Avg HD : 47.11, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [36/100], Batch: [25/45], Loss: 0.2352,                   Dice: 56.90, HD: 32.75\n\nEpoch: [36/100], Avg Loss: 0.495,               Train Dice: 56.19, Train HD: 33.24, Time : 11 sec\nAdjusting learning rate of group 0 to 7.1289e-04.\n\n\nEpoch: [37/100], Batch: [25/45], Loss: 0.4552,                   Dice: 60.26, HD: 28.85\n\nEpoch: [37/100], Avg Loss: 0.489,               Train Dice: 58.71, Train HD: 29.14, Time : 12 sec\nAdjusting learning rate of group 0 to 6.9857e-04.\n\n\nEpoch: [38/100], Batch: [25/45], Loss: 0.5288,                   Dice: 64.79, HD: 21.86\n\nEpoch: [38/100], Avg Loss: 0.470,               Train Dice: 58.46, Train HD: 26.88, Time : 11 sec\nAdjusting learning rate of group 0 to 6.8406e-04.\n\n\nEpoch: [39/100], Batch: [25/45], Loss: 0.5296,                   Dice: 61.99, HD: 28.06\n\nEpoch: [39/100], Avg Loss: 0.509,               Train Dice: 54.64, Train HD: 33.98, Time : 11 sec\nAdjusting learning rate of group 0 to 6.6937e-04.\n\n\nEpoch: [40/100], Batch: [25/45], Loss: 0.5000,                   Dice: 58.34, HD: 25.71\n\nEpoch: [40/100], Avg Loss: 0.497,               Train Dice: 55.43, Train HD: 29.33, Time : 12 sec\nAdjusting learning rate of group 0 to 6.5451e-04.\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : PROMISE12, Test Avg Dice : 79.33, Test Avg HD : 17.26, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [41/100], Batch: [25/45], Loss: 0.4057,                   Dice: 49.61, HD: 38.14\n\nEpoch: [41/100], Avg Loss: 0.494,               Train Dice: 53.26, Train HD: 33.70, Time : 11 sec\nAdjusting learning rate of group 0 to 6.3950e-04.\n\n\nEpoch: [42/100], Batch: [25/45], Loss: 0.5182,                   Dice: 60.51, HD: 27.50\n\nEpoch: [42/100], Avg Loss: 0.451,               Train Dice: 60.63, Train HD: 27.59, Time : 12 sec\nAdjusting learning rate of group 0 to 6.2434e-04.\n\n\nEpoch: [43/100], Batch: [25/45], Loss: 0.4814,                   Dice: 55.86, HD: 28.24\n\nEpoch: [43/100], Avg Loss: 0.459,               Train Dice: 59.37, Train HD: 27.59, Time : 11 sec\nAdjusting learning rate of group 0 to 6.0907e-04.\n\n\nEpoch: [44/100], Batch: [25/45], Loss: 0.5369,                   Dice: 56.61, HD: 30.67\n\nEpoch: [44/100], Avg Loss: 0.481,               Train Dice: 59.61, Train HD: 27.78, Time : 11 sec\nAdjusting learning rate of group 0 to 5.9369e-04.\n\n\nEpoch: [45/100], Batch: [25/45], Loss: 0.3664,                   Dice: 60.49, HD: 29.79\n\nEpoch: [45/100], Avg Loss: 0.482,               Train Dice: 63.00, Train HD: 25.61, Time : 11 sec\nAdjusting learning rate of group 0 to 5.7822e-04.\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : PROMISE12, Test Avg Dice : 75.60, Test Avg HD : 19.93, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [46/100], Batch: [25/45], Loss: 0.5906,                   Dice: 45.87, HD: 43.12\n\nEpoch: [46/100], Avg Loss: 0.518,               Train Dice: 49.10, Train HD: 36.93, Time : 11 sec\nAdjusting learning rate of group 0 to 5.6267e-04.\n\n\nEpoch: [47/100], Batch: [25/45], Loss: 0.5181,                   Dice: 57.18, HD: 34.42\n\nEpoch: [47/100], Avg Loss: 0.501,               Train Dice: 58.46, Train HD: 30.12, Time : 11 sec\nAdjusting learning rate of group 0 to 5.4705e-04.\n\n\nEpoch: [48/100], Batch: [25/45], Loss: 0.3432,                   Dice: 57.82, HD: 30.86\n\nEpoch: [48/100], Avg Loss: 0.509,               Train Dice: 57.11, Train HD: 31.34, Time : 11 sec\nAdjusting learning rate of group 0 to 5.3140e-04.\n\n\nEpoch: [49/100], Batch: [25/45], Loss: 0.3622,                   Dice: 63.59, HD: 25.60\n\nEpoch: [49/100], Avg Loss: 0.460,               Train Dice: 63.80, Train HD: 24.51, Time : 12 sec\nAdjusting learning rate of group 0 to 5.1571e-04.\n\n\nEpoch: [50/100], Batch: [25/45], Loss: 0.3595,                   Dice: 62.63, HD: 25.03\n\nEpoch: [50/100], Avg Loss: 0.453,               Train Dice: 61.87, Train HD: 25.62, Time : 11 sec\nAdjusting learning rate of group 0 to 5.0000e-04.\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : PROMISE12, Test Avg Dice : 80.86, Test Avg HD : 16.34, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [51/100], Batch: [25/45], Loss: 0.3991,                   Dice: 70.12, HD: 17.97\n\nEpoch: [51/100], Avg Loss: 0.478,               Train Dice: 67.09, Train HD: 24.17, Time : 11 sec\nAdjusting learning rate of group 0 to 4.8429e-04.\n\n\nEpoch: [52/100], Batch: [25/45], Loss: 0.4757,                   Dice: 63.64, HD: 19.10\n\nEpoch: [52/100], Avg Loss: 0.430,               Train Dice: 66.31, Train HD: 18.97, Time : 11 sec\nAdjusting learning rate of group 0 to 4.6860e-04.\n\n\nEpoch: [53/100], Batch: [25/45], Loss: 0.4893,                   Dice: 65.03, HD: 24.22\n\nEpoch: [53/100], Avg Loss: 0.435,               Train Dice: 66.58, Train HD: 22.22, Time : 11 sec\nAdjusting learning rate of group 0 to 4.5295e-04.\n\n\nEpoch: [54/100], Batch: [25/45], Loss: 0.1589,                   Dice: 63.50, HD: 25.43\n\nEpoch: [54/100], Avg Loss: 0.464,               Train Dice: 63.87, Train HD: 25.40, Time : 12 sec\nAdjusting learning rate of group 0 to 4.3733e-04.\n\n\nEpoch: [55/100], Batch: [25/45], Loss: 0.4195,                   Dice: 63.16, HD: 25.80\n\nEpoch: [55/100], Avg Loss: 0.441,               Train Dice: 67.19, Train HD: 23.08, Time : 11 sec\nAdjusting learning rate of group 0 to 4.2178e-04.\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : PROMISE12, Test Avg Dice : 82.32, Test Avg HD : 15.46, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [56/100], Batch: [25/45], Loss: 0.3891,                   Dice: 65.00, HD: 22.32\n\nEpoch: [56/100], Avg Loss: 0.442,               Train Dice: 61.67, Train HD: 25.50, Time : 11 sec\nAdjusting learning rate of group 0 to 4.0631e-04.\n\n\nEpoch: [57/100], Batch: [25/45], Loss: 0.5910,                   Dice: 65.00, HD: 22.22\n\nEpoch: [57/100], Avg Loss: 0.460,               Train Dice: 63.62, Train HD: 25.49, Time : 11 sec\nAdjusting learning rate of group 0 to 3.9093e-04.\n\n\nEpoch: [58/100], Batch: [25/45], Loss: 0.1667,                   Dice: 69.53, HD: 19.26\n\nEpoch: [58/100], Avg Loss: 0.431,               Train Dice: 67.95, Train HD: 21.59, Time : 11 sec\nAdjusting learning rate of group 0 to 3.7566e-04.\n\n\nEpoch: [59/100], Batch: [25/45], Loss: 0.5669,                   Dice: 59.55, HD: 30.06\n\nEpoch: [59/100], Avg Loss: 0.452,               Train Dice: 62.24, Train HD: 26.18, Time : 12 sec\nAdjusting learning rate of group 0 to 3.6050e-04.\n\n\nEpoch: [60/100], Batch: [25/45], Loss: 0.3093,                   Dice: 69.76, HD: 20.82\n\nEpoch: [60/100], Avg Loss: 0.422,               Train Dice: 65.38, Train HD: 19.87, Time : 11 sec\nAdjusting learning rate of group 0 to 3.4549e-04.\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : PROMISE12, Test Avg Dice : 81.21, Test Avg HD : 15.79, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [61/100], Batch: [25/45], Loss: 0.5149,                   Dice: 64.38, HD: 30.39\n\nEpoch: [61/100], Avg Loss: 0.449,               Train Dice: 61.54, Train HD: 27.01, Time : 11 sec\nAdjusting learning rate of group 0 to 3.3063e-04.\n\n\nEpoch: [62/100], Batch: [25/45], Loss: 0.2323,                   Dice: 72.28, HD: 20.19\n\nEpoch: [62/100], Avg Loss: 0.406,               Train Dice: 70.32, Train HD: 20.93, Time : 11 sec\nAdjusting learning rate of group 0 to 3.1594e-04.\n\n\nEpoch: [63/100], Batch: [25/45], Loss: 0.3726,                   Dice: 69.48, HD: 19.81\n\nEpoch: [63/100], Avg Loss: 0.425,               Train Dice: 67.47, Train HD: 21.09, Time : 11 sec\nAdjusting learning rate of group 0 to 3.0143e-04.\n\n\nEpoch: [64/100], Batch: [25/45], Loss: 0.3060,                   Dice: 68.18, HD: 17.67\n\nEpoch: [64/100], Avg Loss: 0.439,               Train Dice: 66.45, Train HD: 19.92, Time : 11 sec\nAdjusting learning rate of group 0 to 2.8711e-04.\n\n\nEpoch: [65/100], Batch: [25/45], Loss: 0.4008,                   Dice: 67.94, HD: 16.22\n\nEpoch: [65/100], Avg Loss: 0.417,               Train Dice: 69.30, Train HD: 19.12, Time : 11 sec\nAdjusting learning rate of group 0 to 2.7300e-04.\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : PROMISE12, Test Avg Dice : 82.60, Test Avg HD : 15.45, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [66/100], Batch: [25/45], Loss: 0.2980,                   Dice: 73.27, HD: 20.05\n\nEpoch: [66/100], Avg Loss: 0.422,               Train Dice: 71.16, Train HD: 20.43, Time : 11 sec\nAdjusting learning rate of group 0 to 2.5912e-04.\n\n\nEpoch: [67/100], Batch: [25/45], Loss: 0.3145,                   Dice: 72.11, HD: 18.12\n\nEpoch: [67/100], Avg Loss: 0.409,               Train Dice: 69.12, Train HD: 19.20, Time : 11 sec\nAdjusting learning rate of group 0 to 2.4548e-04.\n\n\nEpoch: [68/100], Batch: [25/45], Loss: 0.3689,                   Dice: 74.00, HD: 21.54\n\nEpoch: [68/100], Avg Loss: 0.415,               Train Dice: 71.30, Train HD: 20.50, Time : 11 sec\nAdjusting learning rate of group 0 to 2.3209e-04.\n\n\nEpoch: [69/100], Batch: [25/45], Loss: 0.3780,                   Dice: 62.80, HD: 22.01\n\nEpoch: [69/100], Avg Loss: 0.406,               Train Dice: 68.78, Train HD: 18.30, Time : 11 sec\nAdjusting learning rate of group 0 to 2.1896e-04.\n\n\nEpoch: [70/100], Batch: [25/45], Loss: 0.3382,                   Dice: 71.42, HD: 17.65\n\nEpoch: [70/100], Avg Loss: 0.397,               Train Dice: 74.56, Train HD: 16.22, Time : 11 sec\nAdjusting learning rate of group 0 to 2.0611e-04.\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : PROMISE12, Test Avg Dice : 83.64, Test Avg HD : 14.35, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [71/100], Batch: [25/45], Loss: 0.3776,                   Dice: 76.05, HD: 15.04\n\nEpoch: [71/100], Avg Loss: 0.399,               Train Dice: 72.03, Train HD: 15.59, Time : 11 sec\nAdjusting learning rate of group 0 to 1.9355e-04.\n\n\nEpoch: [72/100], Batch: [25/45], Loss: 0.3842,                   Dice: 75.32, HD: 14.81\n\nEpoch: [72/100], Avg Loss: 0.411,               Train Dice: 73.42, Train HD: 18.14, Time : 11 sec\nAdjusting learning rate of group 0 to 1.8129e-04.\n\n\nEpoch: [73/100], Batch: [25/45], Loss: 0.5071,                   Dice: 73.58, HD: 18.72\n\nEpoch: [73/100], Avg Loss: 0.398,               Train Dice: 71.97, Train HD: 19.09, Time : 11 sec\nAdjusting learning rate of group 0 to 1.6934e-04.\n\n\nEpoch: [74/100], Batch: [25/45], Loss: 0.3915,                   Dice: 77.00, HD: 17.93\n\nEpoch: [74/100], Avg Loss: 0.377,               Train Dice: 76.15, Train HD: 16.86, Time : 11 sec\nAdjusting learning rate of group 0 to 1.5773e-04.\n\n\nEpoch: [75/100], Batch: [25/45], Loss: 0.5063,                   Dice: 73.54, HD: 17.31\n\nEpoch: [75/100], Avg Loss: 0.402,               Train Dice: 69.39, Train HD: 20.15, Time : 11 sec\nAdjusting learning rate of group 0 to 1.4645e-04.\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : PROMISE12, Test Avg Dice : 85.86, Test Avg HD : 13.43, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [76/100], Batch: [25/45], Loss: 0.3166,                   Dice: 77.41, HD: 14.20\n\nEpoch: [76/100], Avg Loss: 0.410,               Train Dice: 71.88, Train HD: 21.80, Time : 12 sec\nAdjusting learning rate of group 0 to 1.3552e-04.\n\n\nEpoch: [77/100], Batch: [25/45], Loss: 0.5091,                   Dice: 74.91, HD: 18.06\n\nEpoch: [77/100], Avg Loss: 0.386,               Train Dice: 72.35, Train HD: 16.35, Time : 11 sec\nAdjusting learning rate of group 0 to 1.2494e-04.\n\n\nEpoch: [78/100], Batch: [25/45], Loss: 0.3611,                   Dice: 63.08, HD: 21.12\n\nEpoch: [78/100], Avg Loss: 0.383,               Train Dice: 71.20, Train HD: 16.68, Time : 11 sec\nAdjusting learning rate of group 0 to 1.1474e-04.\n\n\nEpoch: [79/100], Batch: [25/45], Loss: 0.3227,                   Dice: 72.41, HD: 15.88\n\nEpoch: [79/100], Avg Loss: 0.408,               Train Dice: 70.85, Train HD: 18.31, Time : 11 sec\nAdjusting learning rate of group 0 to 1.0492e-04.\n\n\nEpoch: [80/100], Batch: [25/45], Loss: 0.5094,                   Dice: 74.18, HD: 20.56\n\nEpoch: [80/100], Avg Loss: 0.394,               Train Dice: 73.91, Train HD: 18.98, Time : 11 sec\nAdjusting learning rate of group 0 to 9.5492e-05.\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : PROMISE12, Test Avg Dice : 83.82, Test Avg HD : 14.17, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [81/100], Batch: [25/45], Loss: 0.3020,                   Dice: 59.89, HD: 21.00\n\nEpoch: [81/100], Avg Loss: 0.395,               Train Dice: 66.83, Train HD: 17.98, Time : 11 sec\nAdjusting learning rate of group 0 to 8.6460e-05.\n\n\nEpoch: [82/100], Batch: [25/45], Loss: 0.2909,                   Dice: 76.69, HD: 17.33\n\nEpoch: [82/100], Avg Loss: 0.379,               Train Dice: 74.26, Train HD: 17.32, Time : 11 sec\nAdjusting learning rate of group 0 to 7.7836e-05.\n\n\nEpoch: [83/100], Batch: [25/45], Loss: 0.2338,                   Dice: 67.04, HD: 18.74\n\nEpoch: [83/100], Avg Loss: 0.385,               Train Dice: 71.30, Train HD: 17.36, Time : 11 sec\nAdjusting learning rate of group 0 to 6.9629e-05.\n\n\nEpoch: [84/100], Batch: [25/45], Loss: 0.2700,                   Dice: 74.75, HD: 16.31\n\nEpoch: [84/100], Avg Loss: 0.393,               Train Dice: 70.85, Train HD: 18.10, Time : 11 sec\nAdjusting learning rate of group 0 to 6.1847e-05.\n\n\nEpoch: [85/100], Batch: [25/45], Loss: 0.2185,                   Dice: 76.67, HD: 16.38\n\nEpoch: [85/100], Avg Loss: 0.381,               Train Dice: 75.24, Train HD: 16.64, Time : 11 sec\nAdjusting learning rate of group 0 to 5.4497e-05.\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : PROMISE12, Test Avg Dice : 86.12, Test Avg HD : 12.97, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [86/100], Batch: [25/45], Loss: 0.5092,                   Dice: 73.90, HD: 17.18\n\nEpoch: [86/100], Avg Loss: 0.389,               Train Dice: 76.74, Train HD: 15.78, Time : 11 sec\nAdjusting learning rate of group 0 to 4.7586e-05.\n\n\nEpoch: [87/100], Batch: [25/45], Loss: 0.3626,                   Dice: 64.75, HD: 21.40\n\nEpoch: [87/100], Avg Loss: 0.397,               Train Dice: 70.44, Train HD: 18.31, Time : 11 sec\nAdjusting learning rate of group 0 to 4.1123e-05.\n\n\nEpoch: [88/100], Batch: [25/45], Loss: 0.5170,                   Dice: 65.62, HD: 20.40\n\nEpoch: [88/100], Avg Loss: 0.388,               Train Dice: 71.01, Train HD: 16.56, Time : 11 sec\nAdjusting learning rate of group 0 to 3.5112e-05.\n\n\nEpoch: [89/100], Batch: [25/45], Loss: 0.3109,                   Dice: 80.11, HD: 12.36\n\nEpoch: [89/100], Avg Loss: 0.381,               Train Dice: 75.33, Train HD: 14.33, Time : 11 sec\nAdjusting learning rate of group 0 to 2.9560e-05.\n\n\nEpoch: [90/100], Batch: [25/45], Loss: 0.3489,                   Dice: 70.77, HD: 15.05\n\nEpoch: [90/100], Avg Loss: 0.381,               Train Dice: 73.97, Train HD: 16.50, Time : 11 sec\nAdjusting learning rate of group 0 to 2.4472e-05.\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : PROMISE12, Test Avg Dice : 86.19, Test Avg HD : 12.84, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [91/100], Batch: [25/45], Loss: 0.3949,                   Dice: 78.81, HD: 14.08\n\nEpoch: [91/100], Avg Loss: 0.368,               Train Dice: 78.38, Train HD: 13.71, Time : 11 sec\nAdjusting learning rate of group 0 to 1.9853e-05.\n\n\nEpoch: [92/100], Batch: [25/45], Loss: 0.3771,                   Dice: 78.76, HD: 13.43\n\nEpoch: [92/100], Avg Loss: 0.377,               Train Dice: 75.69, Train HD: 14.95, Time : 11 sec\nAdjusting learning rate of group 0 to 1.5708e-05.\n\n\nEpoch: [93/100], Batch: [25/45], Loss: 0.5114,                   Dice: 75.48, HD: 14.47\n\nEpoch: [93/100], Avg Loss: 0.381,               Train Dice: 74.89, Train HD: 14.72, Time : 11 sec\nAdjusting learning rate of group 0 to 1.2042e-05.\n\n\nEpoch: [94/100], Batch: [25/45], Loss: 0.3178,                   Dice: 75.12, HD: 18.53\n\nEpoch: [94/100], Avg Loss: 0.368,               Train Dice: 76.54, Train HD: 16.62, Time : 11 sec\nAdjusting learning rate of group 0 to 8.8564e-06.\n\n\nEpoch: [95/100], Batch: [25/45], Loss: 0.5330,                   Dice: 74.74, HD: 17.04\n\nEpoch: [95/100], Avg Loss: 0.386,               Train Dice: 74.71, Train HD: 16.41, Time : 11 sec\nAdjusting learning rate of group 0 to 6.1558e-06.\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : PROMISE12, Test Avg Dice : 86.69, Test Avg HD : 12.68, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [96/100], Batch: [25/45], Loss: 0.5127,                   Dice: 74.05, HD: 16.17\n\nEpoch: [96/100], Avg Loss: 0.388,               Train Dice: 75.16, Train HD: 16.62, Time : 11 sec\nAdjusting learning rate of group 0 to 3.9426e-06.\n\n\nEpoch: [97/100], Batch: [25/45], Loss: 0.3138,                   Dice: 80.03, HD: 12.65\n\nEpoch: [97/100], Avg Loss: 0.371,               Train Dice: 80.43, Train HD: 12.70, Time : 11 sec\nAdjusting learning rate of group 0 to 2.2190e-06.\n\n\nEpoch: [98/100], Batch: [25/45], Loss: 0.3296,                   Dice: 66.63, HD: 22.91\n\nEpoch: [98/100], Avg Loss: 0.391,               Train Dice: 71.22, Train HD: 19.30, Time : 11 sec\nAdjusting learning rate of group 0 to 9.8664e-07.\n\n\nEpoch: [99/100], Batch: [25/45], Loss: 0.2545,                   Dice: 74.22, HD: 16.50\n\nEpoch: [99/100], Avg Loss: 0.369,               Train Dice: 76.67, Train HD: 15.15, Time : 11 sec\nAdjusting learning rate of group 0 to 2.4672e-07.\n\n\nEpoch: [100/100], Batch: [25/45], Loss: 0.3624,                   Dice: 61.03, HD: 19.55\n\nEpoch: [100/100], Avg Loss: 0.400,               Train Dice: 69.10, Train HD: 16.21, Time : 11 sec\nAdjusting learning rate of group 0 to 0.0000e+00.\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : PROMISE12, Test Avg Dice : 86.70, Test Avg HD : 12.63, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Store few samples to replay memory buffer","metadata":{}},{"cell_type":"code","source":"replay_percentage = 0.1\ntrain_samples_count = len(dataset_map[dataset_name]['train']['images'])\nreplay_count = int(train_samples_count * replay_percentage)\nprint(f\"Storing {replay_count} Promise 12 Samples to replay buffer\")\nidxs = idxs = list(map(int, np.linspace(0, train_samples_count-1, num=replay_count).tolist()))\nreplay_buffer['train']['images'] +=  [dataset_map[dataset_name]['train']['images'][idx] for idx in idxs]\nreplay_buffer['train']['labels'] +=  [dataset_map[dataset_name]['train']['labels'][idx] for idx in idxs]\nprint(f\"Current replay buffer size : {len(replay_buffer['train']['labels'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:40:36.711937Z","iopub.execute_input":"2022-09-10T08:40:36.712504Z","iopub.status.idle":"2022-09-10T08:40:36.723939Z","shell.execute_reply.started":"2022-09-10T08:40:36.712468Z","shell.execute_reply":"2022-09-10T08:40:36.722398Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Storing 4 Promise 12 Samples to replay buffer\nCurrent replay buffer size : 4\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Train on ISBI --> Test on Promise12 & ISBI\n\nepochs = 100\ninitial_lr = 1e-3\noptimizer = Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n# optimizer = ASGD(model.parameters(), lr=initial_lr)\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=True)\n\n\ndataset_name = 'isbi'\n# img_paths = dataset_map[dataset_name]['train']['images'] + replay_buffer['train']['images']\n# label_paths = dataset_map[dataset_name]['train']['labels'] + replay_buffer['train']['labels']\n\nimg_paths = dataset_map[dataset_name]['train']['images'] \nlabel_paths = dataset_map[dataset_name]['train']['labels'] \n\ntrain_loader = get_dataloader(img_paths = img_paths,\n                           label_paths = label_paths,\n                           train = True)\n\nem_loader = get_dataloader(img_paths = replay_buffer['train']['images'],\n                              label_paths = replay_buffer['train']['labels'],\n                              train = True)\n\ntest_dataset_names = ['promise12', 'isbi']\n\nmetric_prefix  += 'isbi->'\n\nmetrics_map = {}\nfor dname in test_dataset_names:\n    metrics_map[dname] = {\n        f'{metric_prefix}_{dname}_curr_dice' : 0,\n        f'{metric_prefix}_{dname}_best_dice' : 0,\n        f'{metric_prefix}_{dname}_curr_hd' : 1e10,\n        f'{metric_prefix}_{dname}_best_hd' : 1e10,\n        'Epoch' : 0\n    }\n\nfor epoch in range(1, epochs+1):   \n        train(train_loader = train_loader, em_loader = em_loader)\n        \n        if epoch % val_interval == 0:\n            for dname in test_dataset_names:\n                val_dice, val_hd = validate(test_loader = dataloaders_map[dname]['test'], dataset_name = dname)\n\n                val_dice *= 100\n\n                metrics = metrics_map[dname]\n\n                metrics[f'Epoch'] = epoch\n                metrics[f'{metric_prefix}_{dname}_curr_dice'] = val_dice \n                metrics[f'{metric_prefix}_{dname}_curr_hd'] = val_hd\n                metrics[f'{metric_prefix}_{dname}_best_dice'] = max(val_dice, metrics[f'{metric_prefix}_{dname}_best_dice'])\n\n                if val_hd < metrics[f'{metric_prefix}_{dname}_best_hd'] and val_hd > 0:\n                    metrics[f'{metric_prefix}_{dname}_best_hd'] = val_hd\n\n                if wandb_log:\n                    # Quantiative metrics\n                    wandb.log(metrics)\n                    print('Logged data to wandb')","metadata":{"execution":{"iopub.status.busy":"2022-09-10T08:40:36.725185Z","iopub.execute_input":"2022-09-10T08:40:36.725505Z","iopub.status.idle":"2022-09-10T09:36:49.848588Z","shell.execute_reply.started":"2022-09-10T08:40:36.725475Z","shell.execute_reply":"2022-09-10T09:36:49.847644Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n\n\nEpoch: [1/100], Batch: [25/63], Loss: 0.6046,                   Dice: 58.43, HD: 24.58\nEpoch: [1/100], Batch: [50/63], Loss: 0.4705,                   Dice: 64.39, HD: 22.09\n\nEpoch: [1/100], Avg Loss: 0.446,               Train Dice: 63.60, Train HD: 23.29, Time : 49 sec\nAdjusting learning rate of group 0 to 9.9975e-04.\n\n\nEpoch: [2/100], Batch: [25/63], Loss: 0.4831,                   Dice: 66.90, HD: 23.24\nEpoch: [2/100], Batch: [50/63], Loss: 0.4426,                   Dice: 65.45, HD: 23.29\n\nEpoch: [2/100], Avg Loss: 0.436,               Train Dice: 65.93, Train HD: 22.47, Time : 29 sec\nAdjusting learning rate of group 0 to 9.9901e-04.\n\n\nEpoch: [3/100], Batch: [25/63], Loss: 0.4757,                   Dice: 66.24, HD: 19.35\nEpoch: [3/100], Batch: [50/63], Loss: 0.2772,                   Dice: 71.11, HD: 17.70\n\nEpoch: [3/100], Avg Loss: 0.408,               Train Dice: 71.65, Train HD: 17.53, Time : 28 sec\nAdjusting learning rate of group 0 to 9.9778e-04.\n\n\nEpoch: [4/100], Batch: [25/63], Loss: 0.3233,                   Dice: 69.44, HD: 20.75\nEpoch: [4/100], Batch: [50/63], Loss: 0.3686,                   Dice: 70.49, HD: 20.91\n\nEpoch: [4/100], Avg Loss: 0.443,               Train Dice: 69.20, Train HD: 20.88, Time : 29 sec\nAdjusting learning rate of group 0 to 9.9606e-04.\n\n\nEpoch: [5/100], Batch: [25/63], Loss: 0.2410,                   Dice: 69.91, HD: 18.38\nEpoch: [5/100], Batch: [50/63], Loss: 0.4247,                   Dice: 67.85, HD: 20.18\n\nEpoch: [5/100], Avg Loss: 0.432,               Train Dice: 67.51, Train HD: 20.65, Time : 30 sec\nAdjusting learning rate of group 0 to 9.9384e-04.\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : PROMISE12, Test Avg Dice : 69.61, Test Avg HD : 19.96, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : ISBI, Test Avg Dice : 59.35, Test Avg HD : 32.14, Time : 20 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [6/100], Batch: [25/63], Loss: 0.2738,                   Dice: 71.61, HD: 17.83\nEpoch: [6/100], Batch: [50/63], Loss: 0.4456,                   Dice: 71.64, HD: 17.16\n\nEpoch: [6/100], Avg Loss: 0.424,               Train Dice: 71.50, Train HD: 16.83, Time : 31 sec\nAdjusting learning rate of group 0 to 9.9114e-04.\n\n\nEpoch: [7/100], Batch: [25/63], Loss: 0.3912,                   Dice: 73.09, HD: 15.65\nEpoch: [7/100], Batch: [50/63], Loss: 0.3635,                   Dice: 72.59, HD: 15.90\n\nEpoch: [7/100], Avg Loss: 0.406,               Train Dice: 73.27, Train HD: 15.67, Time : 30 sec\nAdjusting learning rate of group 0 to 9.8796e-04.\n\n\nEpoch: [8/100], Batch: [25/63], Loss: 0.4837,                   Dice: 66.07, HD: 22.87\nEpoch: [8/100], Batch: [50/63], Loss: 0.4063,                   Dice: 68.29, HD: 21.29\n\nEpoch: [8/100], Avg Loss: 0.426,               Train Dice: 68.48, Train HD: 20.84, Time : 32 sec\nAdjusting learning rate of group 0 to 9.8429e-04.\n\n\nEpoch: [9/100], Batch: [25/63], Loss: 0.3624,                   Dice: 73.12, HD: 17.37\nEpoch: [9/100], Batch: [50/63], Loss: 0.2053,                   Dice: 72.40, HD: 18.23\n\nEpoch: [9/100], Avg Loss: 0.404,               Train Dice: 71.34, Train HD: 18.87, Time : 29 sec\nAdjusting learning rate of group 0 to 9.8015e-04.\n\n\nEpoch: [10/100], Batch: [25/63], Loss: 0.3912,                   Dice: 79.97, HD: 14.07\nEpoch: [10/100], Batch: [50/63], Loss: 0.4289,                   Dice: 76.29, HD: 15.58\n\nEpoch: [10/100], Avg Loss: 0.387,               Train Dice: 76.65, Train HD: 15.42, Time : 28 sec\nAdjusting learning rate of group 0 to 9.7553e-04.\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : PROMISE12, Test Avg Dice : 82.87, Test Avg HD : 15.86, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : ISBI, Test Avg Dice : 71.66, Test Avg HD : 29.86, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [11/100], Batch: [25/63], Loss: 0.6699,                   Dice: 72.99, HD: 18.35\nEpoch: [11/100], Batch: [50/63], Loss: 0.3543,                   Dice: 71.80, HD: 18.42\n\nEpoch: [11/100], Avg Loss: 0.420,               Train Dice: 72.25, Train HD: 18.29, Time : 29 sec\nAdjusting learning rate of group 0 to 9.7044e-04.\n\n\nEpoch: [12/100], Batch: [25/63], Loss: 0.4669,                   Dice: 73.79, HD: 16.26\nEpoch: [12/100], Batch: [50/63], Loss: 0.4036,                   Dice: 73.29, HD: 17.12\n\nEpoch: [12/100], Avg Loss: 0.406,               Train Dice: 73.53, Train HD: 17.13, Time : 31 sec\nAdjusting learning rate of group 0 to 9.6489e-04.\n\n\nEpoch: [13/100], Batch: [25/63], Loss: 0.3747,                   Dice: 69.89, HD: 17.51\nEpoch: [13/100], Batch: [50/63], Loss: 0.2256,                   Dice: 72.63, HD: 17.09\n\nEpoch: [13/100], Avg Loss: 0.412,               Train Dice: 72.80, Train HD: 17.31, Time : 29 sec\nAdjusting learning rate of group 0 to 9.5888e-04.\n\n\nEpoch: [14/100], Batch: [25/63], Loss: 0.3511,                   Dice: 67.67, HD: 16.23\nEpoch: [14/100], Batch: [50/63], Loss: 0.3953,                   Dice: 70.91, HD: 16.69\n\nEpoch: [14/100], Avg Loss: 0.415,               Train Dice: 71.71, Train HD: 16.38, Time : 29 sec\nAdjusting learning rate of group 0 to 9.5241e-04.\n\n\nEpoch: [15/100], Batch: [25/63], Loss: 0.5114,                   Dice: 75.54, HD: 16.00\nEpoch: [15/100], Batch: [50/63], Loss: 0.4352,                   Dice: 73.68, HD: 16.44\n\nEpoch: [15/100], Avg Loss: 0.413,               Train Dice: 72.67, Train HD: 16.59, Time : 33 sec\nAdjusting learning rate of group 0 to 9.4550e-04.\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : PROMISE12, Test Avg Dice : 85.16, Test Avg HD : 12.89, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : ISBI, Test Avg Dice : 72.55, Test Avg HD : 23.81, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [16/100], Batch: [25/63], Loss: 0.1783,                   Dice: 79.07, HD: 14.31\nEpoch: [16/100], Batch: [50/63], Loss: 0.5248,                   Dice: 77.76, HD: 14.62\n\nEpoch: [16/100], Avg Loss: 0.402,               Train Dice: 76.57, Train HD: 14.92, Time : 30 sec\nAdjusting learning rate of group 0 to 9.3815e-04.\n\n\nEpoch: [17/100], Batch: [25/63], Loss: 0.3917,                   Dice: 75.66, HD: 16.09\nEpoch: [17/100], Batch: [50/63], Loss: 0.4224,                   Dice: 75.74, HD: 14.99\n\nEpoch: [17/100], Avg Loss: 0.402,               Train Dice: 76.08, Train HD: 14.67, Time : 29 sec\nAdjusting learning rate of group 0 to 9.3037e-04.\n\n\nEpoch: [18/100], Batch: [25/63], Loss: 0.4629,                   Dice: 77.72, HD: 14.27\nEpoch: [18/100], Batch: [50/63], Loss: 0.3821,                   Dice: 77.36, HD: 14.49\n\nEpoch: [18/100], Avg Loss: 0.382,               Train Dice: 75.85, Train HD: 15.14, Time : 31 sec\nAdjusting learning rate of group 0 to 9.2216e-04.\n\n\nEpoch: [19/100], Batch: [25/63], Loss: 0.3864,                   Dice: 75.71, HD: 14.92\nEpoch: [19/100], Batch: [50/63], Loss: 0.3626,                   Dice: 76.81, HD: 14.67\n\nEpoch: [19/100], Avg Loss: 0.387,               Train Dice: 77.08, Train HD: 14.52, Time : 29 sec\nAdjusting learning rate of group 0 to 9.1354e-04.\n\n\nEpoch: [20/100], Batch: [25/63], Loss: 0.3169,                   Dice: 77.99, HD: 14.28\nEpoch: [20/100], Batch: [50/63], Loss: 0.3813,                   Dice: 75.93, HD: 14.74\n\nEpoch: [20/100], Avg Loss: 0.397,               Train Dice: 77.29, Train HD: 14.86, Time : 29 sec\nAdjusting learning rate of group 0 to 9.0451e-04.\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : PROMISE12, Test Avg Dice : 73.61, Test Avg HD : 25.70, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : ISBI, Test Avg Dice : 70.96, Test Avg HD : 28.52, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [21/100], Batch: [25/63], Loss: 0.4283,                   Dice: 75.90, HD: 15.34\nEpoch: [21/100], Batch: [50/63], Loss: 0.3937,                   Dice: 76.00, HD: 16.35\n\nEpoch: [21/100], Avg Loss: 0.399,               Train Dice: 76.03, Train HD: 15.75, Time : 31 sec\nAdjusting learning rate of group 0 to 8.9508e-04.\n\n\nEpoch: [22/100], Batch: [25/63], Loss: 0.3814,                   Dice: 82.03, HD: 12.14\nEpoch: [22/100], Batch: [50/63], Loss: 0.4869,                   Dice: 81.26, HD: 11.90\n\nEpoch: [22/100], Avg Loss: 0.377,               Train Dice: 80.72, Train HD: 12.09, Time : 26 sec\nAdjusting learning rate of group 0 to 8.8526e-04.\n\n\nEpoch: [23/100], Batch: [25/63], Loss: 0.3287,                   Dice: 77.51, HD: 14.28\nEpoch: [23/100], Batch: [50/63], Loss: 0.5223,                   Dice: 79.74, HD: 12.19\n\nEpoch: [23/100], Avg Loss: 0.382,               Train Dice: 78.97, Train HD: 13.09, Time : 27 sec\nAdjusting learning rate of group 0 to 8.7506e-04.\n\n\nEpoch: [24/100], Batch: [25/63], Loss: 0.3335,                   Dice: 81.40, HD: 13.11\nEpoch: [24/100], Batch: [50/63], Loss: 0.4569,                   Dice: 80.81, HD: 12.73\n\nEpoch: [24/100], Avg Loss: 0.381,               Train Dice: 80.62, Train HD: 13.18, Time : 30 sec\nAdjusting learning rate of group 0 to 8.6448e-04.\n\n\nEpoch: [25/100], Batch: [25/63], Loss: 0.4262,                   Dice: 82.06, HD: 11.25\nEpoch: [25/100], Batch: [50/63], Loss: 0.2562,                   Dice: 79.23, HD: 13.24\n\nEpoch: [25/100], Avg Loss: 0.386,               Train Dice: 77.58, Train HD: 13.97, Time : 29 sec\nAdjusting learning rate of group 0 to 8.5355e-04.\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : PROMISE12, Test Avg Dice : 84.95, Test Avg HD : 15.51, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : ISBI, Test Avg Dice : 78.13, Test Avg HD : 22.18, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [26/100], Batch: [25/63], Loss: 0.3671,                   Dice: 77.59, HD: 13.87\nEpoch: [26/100], Batch: [50/63], Loss: 0.4876,                   Dice: 79.03, HD: 12.96\n\nEpoch: [26/100], Avg Loss: 0.381,               Train Dice: 79.05, Train HD: 13.13, Time : 30 sec\nAdjusting learning rate of group 0 to 8.4227e-04.\n\n\nEpoch: [27/100], Batch: [25/63], Loss: 0.3917,                   Dice: 79.29, HD: 12.82\nEpoch: [27/100], Batch: [50/63], Loss: 0.4721,                   Dice: 79.67, HD: 12.54\n\nEpoch: [27/100], Avg Loss: 0.379,               Train Dice: 79.72, Train HD: 12.21, Time : 29 sec\nAdjusting learning rate of group 0 to 8.3066e-04.\n\n\nEpoch: [28/100], Batch: [25/63], Loss: 0.3620,                   Dice: 79.16, HD: 12.54\nEpoch: [28/100], Batch: [50/63], Loss: 0.4076,                   Dice: 79.00, HD: 12.70\n\nEpoch: [28/100], Avg Loss: 0.378,               Train Dice: 78.98, Train HD: 12.67, Time : 32 sec\nAdjusting learning rate of group 0 to 8.1871e-04.\n\n\nEpoch: [29/100], Batch: [25/63], Loss: 0.2626,                   Dice: 82.34, HD: 9.12\nEpoch: [29/100], Batch: [50/63], Loss: 0.4832,                   Dice: 81.62, HD: 10.64\n\nEpoch: [29/100], Avg Loss: 0.372,               Train Dice: 81.94, Train HD: 10.72, Time : 27 sec\nAdjusting learning rate of group 0 to 8.0645e-04.\n\n\nEpoch: [30/100], Batch: [25/63], Loss: 0.4420,                   Dice: 79.29, HD: 11.54\nEpoch: [30/100], Batch: [50/63], Loss: 0.4449,                   Dice: 79.31, HD: 11.63\n\nEpoch: [30/100], Avg Loss: 0.375,               Train Dice: 81.24, Train HD: 10.60, Time : 29 sec\nAdjusting learning rate of group 0 to 7.9389e-04.\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : PROMISE12, Test Avg Dice : 73.68, Test Avg HD : 27.91, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : ISBI, Test Avg Dice : 74.04, Test Avg HD : 23.25, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [31/100], Batch: [25/63], Loss: 0.3674,                   Dice: 74.54, HD: 14.72\nEpoch: [31/100], Batch: [50/63], Loss: 0.4140,                   Dice: 78.83, HD: 12.58\n\nEpoch: [31/100], Avg Loss: 0.384,               Train Dice: 78.51, Train HD: 13.50, Time : 30 sec\nAdjusting learning rate of group 0 to 7.8104e-04.\n\n\nEpoch: [32/100], Batch: [25/63], Loss: 0.4747,                   Dice: 79.81, HD: 11.90\nEpoch: [32/100], Batch: [50/63], Loss: 0.4538,                   Dice: 80.73, HD: 11.43\n\nEpoch: [32/100], Avg Loss: 0.364,               Train Dice: 79.13, Train HD: 12.46, Time : 26 sec\nAdjusting learning rate of group 0 to 7.6791e-04.\n\n\nEpoch: [33/100], Batch: [25/63], Loss: 0.3135,                   Dice: 81.24, HD: 9.53\nEpoch: [33/100], Batch: [50/63], Loss: 0.4503,                   Dice: 78.59, HD: 12.08\n\nEpoch: [33/100], Avg Loss: 0.385,               Train Dice: 79.49, Train HD: 11.77, Time : 30 sec\nAdjusting learning rate of group 0 to 7.5452e-04.\n\n\nEpoch: [34/100], Batch: [25/63], Loss: 0.2091,                   Dice: 80.30, HD: 12.11\nEpoch: [34/100], Batch: [50/63], Loss: 0.4140,                   Dice: 79.98, HD: 12.10\n\nEpoch: [34/100], Avg Loss: 0.364,               Train Dice: 81.26, Train HD: 11.61, Time : 28 sec\nAdjusting learning rate of group 0 to 7.4088e-04.\n\n\nEpoch: [35/100], Batch: [25/63], Loss: 0.3229,                   Dice: 81.14, HD: 11.06\nEpoch: [35/100], Batch: [50/63], Loss: 0.3926,                   Dice: 80.67, HD: 11.32\n\nEpoch: [35/100], Avg Loss: 0.372,               Train Dice: 80.56, Train HD: 11.43, Time : 28 sec\nAdjusting learning rate of group 0 to 7.2700e-04.\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : PROMISE12, Test Avg Dice : 76.87, Test Avg HD : 27.46, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : ISBI, Test Avg Dice : 76.87, Test Avg HD : 20.65, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [36/100], Batch: [25/63], Loss: 0.3413,                   Dice: 79.73, HD: 11.25\nEpoch: [36/100], Batch: [50/63], Loss: 0.4762,                   Dice: 81.95, HD: 11.30\n\nEpoch: [36/100], Avg Loss: 0.369,               Train Dice: 81.81, Train HD: 11.31, Time : 28 sec\nAdjusting learning rate of group 0 to 7.1289e-04.\n\n\nEpoch: [37/100], Batch: [25/63], Loss: 0.3605,                   Dice: 84.50, HD: 10.58\nEpoch: [37/100], Batch: [50/63], Loss: 0.2631,                   Dice: 84.18, HD: 9.95\n\nEpoch: [37/100], Avg Loss: 0.353,               Train Dice: 83.10, Train HD: 10.41, Time : 29 sec\nAdjusting learning rate of group 0 to 6.9857e-04.\n\n\nEpoch: [38/100], Batch: [25/63], Loss: 0.3862,                   Dice: 86.48, HD: 8.78\nEpoch: [38/100], Batch: [50/63], Loss: 0.3257,                   Dice: 84.31, HD: 10.82\n\nEpoch: [38/100], Avg Loss: 0.364,               Train Dice: 83.93, Train HD: 10.62, Time : 29 sec\nAdjusting learning rate of group 0 to 6.8406e-04.\n\n\nEpoch: [39/100], Batch: [25/63], Loss: 0.4294,                   Dice: 79.20, HD: 11.04\nEpoch: [39/100], Batch: [50/63], Loss: 0.2479,                   Dice: 82.76, HD: 9.63\n\nEpoch: [39/100], Avg Loss: 0.355,               Train Dice: 82.44, Train HD: 10.13, Time : 26 sec\nAdjusting learning rate of group 0 to 6.6937e-04.\n\n\nEpoch: [40/100], Batch: [25/63], Loss: 0.4206,                   Dice: 83.13, HD: 10.51\nEpoch: [40/100], Batch: [50/63], Loss: 0.3914,                   Dice: 83.27, HD: 10.39\n\nEpoch: [40/100], Avg Loss: 0.356,               Train Dice: 82.76, Train HD: 10.88, Time : 31 sec\nAdjusting learning rate of group 0 to 6.5451e-04.\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : PROMISE12, Test Avg Dice : 75.59, Test Avg HD : 24.33, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : ISBI, Test Avg Dice : 80.83, Test Avg HD : 20.93, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [41/100], Batch: [25/63], Loss: 0.4481,                   Dice: 81.39, HD: 9.89\nEpoch: [41/100], Batch: [50/63], Loss: 0.4548,                   Dice: 84.21, HD: 9.63\n\nEpoch: [41/100], Avg Loss: 0.367,               Train Dice: 83.45, Train HD: 10.11, Time : 32 sec\nAdjusting learning rate of group 0 to 6.3950e-04.\n\n\nEpoch: [42/100], Batch: [25/63], Loss: 0.4340,                   Dice: 81.66, HD: 11.68\nEpoch: [42/100], Batch: [50/63], Loss: 0.4166,                   Dice: 82.87, HD: 10.98\n\nEpoch: [42/100], Avg Loss: 0.369,               Train Dice: 82.01, Train HD: 11.02, Time : 31 sec\nAdjusting learning rate of group 0 to 6.2434e-04.\n\n\nEpoch: [43/100], Batch: [25/63], Loss: 0.2268,                   Dice: 86.96, HD: 8.37\nEpoch: [43/100], Batch: [50/63], Loss: 0.3566,                   Dice: 83.19, HD: 11.16\n\nEpoch: [43/100], Avg Loss: 0.350,               Train Dice: 84.23, Train HD: 10.35, Time : 29 sec\nAdjusting learning rate of group 0 to 6.0907e-04.\n\n\nEpoch: [44/100], Batch: [25/63], Loss: 0.4023,                   Dice: 86.54, HD: 8.05\nEpoch: [44/100], Batch: [50/63], Loss: 0.3045,                   Dice: 85.98, HD: 9.18\n\nEpoch: [44/100], Avg Loss: 0.366,               Train Dice: 85.37, Train HD: 9.66, Time : 30 sec\nAdjusting learning rate of group 0 to 5.9369e-04.\n\n\nEpoch: [45/100], Batch: [25/63], Loss: 0.3170,                   Dice: 83.85, HD: 10.10\nEpoch: [45/100], Batch: [50/63], Loss: 0.3380,                   Dice: 84.43, HD: 9.33\n\nEpoch: [45/100], Avg Loss: 0.357,               Train Dice: 83.97, Train HD: 9.38, Time : 31 sec\nAdjusting learning rate of group 0 to 5.7822e-04.\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : PROMISE12, Test Avg Dice : 72.61, Test Avg HD : 18.57, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : ISBI, Test Avg Dice : 74.36, Test Avg HD : 20.67, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [46/100], Batch: [25/63], Loss: 0.2617,                   Dice: 85.76, HD: 9.66\nEpoch: [46/100], Batch: [50/63], Loss: 0.4411,                   Dice: 84.46, HD: 9.49\n\nEpoch: [46/100], Avg Loss: 0.359,               Train Dice: 83.51, Train HD: 9.58, Time : 27 sec\nAdjusting learning rate of group 0 to 5.6267e-04.\n\n\nEpoch: [47/100], Batch: [25/63], Loss: 0.3905,                   Dice: 82.02, HD: 8.68\nEpoch: [47/100], Batch: [50/63], Loss: 0.3731,                   Dice: 83.80, HD: 8.26\n\nEpoch: [47/100], Avg Loss: 0.350,               Train Dice: 84.19, Train HD: 8.37, Time : 28 sec\nAdjusting learning rate of group 0 to 5.4705e-04.\n\n\nEpoch: [48/100], Batch: [25/63], Loss: 0.1786,                   Dice: 85.76, HD: 9.65\nEpoch: [48/100], Batch: [50/63], Loss: 0.1939,                   Dice: 84.94, HD: 9.07\n\nEpoch: [48/100], Avg Loss: 0.350,               Train Dice: 84.83, Train HD: 8.90, Time : 29 sec\nAdjusting learning rate of group 0 to 5.3140e-04.\n\n\nEpoch: [49/100], Batch: [25/63], Loss: 0.3288,                   Dice: 86.82, HD: 8.42\nEpoch: [49/100], Batch: [50/63], Loss: 0.3251,                   Dice: 86.85, HD: 8.56\n\nEpoch: [49/100], Avg Loss: 0.343,               Train Dice: 86.72, Train HD: 8.95, Time : 28 sec\nAdjusting learning rate of group 0 to 5.1571e-04.\n\n\nEpoch: [50/100], Batch: [25/63], Loss: 0.2905,                   Dice: 85.83, HD: 7.97\nEpoch: [50/100], Batch: [50/63], Loss: 0.2414,                   Dice: 86.01, HD: 8.28\n\nEpoch: [50/100], Avg Loss: 0.357,               Train Dice: 85.90, Train HD: 8.73, Time : 29 sec\nAdjusting learning rate of group 0 to 5.0000e-04.\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : PROMISE12, Test Avg Dice : 79.34, Test Avg HD : 22.08, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : ISBI, Test Avg Dice : 79.66, Test Avg HD : 26.50, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [51/100], Batch: [25/63], Loss: 0.2009,                   Dice: 85.42, HD: 10.23\nEpoch: [51/100], Batch: [50/63], Loss: 0.4618,                   Dice: 84.18, HD: 9.85\n\nEpoch: [51/100], Avg Loss: 0.357,               Train Dice: 83.48, Train HD: 9.68, Time : 29 sec\nAdjusting learning rate of group 0 to 4.8429e-04.\n\n\nEpoch: [52/100], Batch: [25/63], Loss: 0.2571,                   Dice: 86.18, HD: 9.18\nEpoch: [52/100], Batch: [50/63], Loss: 0.4131,                   Dice: 85.23, HD: 8.91\n\nEpoch: [52/100], Avg Loss: 0.349,               Train Dice: 85.09, Train HD: 8.96, Time : 30 sec\nAdjusting learning rate of group 0 to 4.6860e-04.\n\n\nEpoch: [53/100], Batch: [25/63], Loss: 0.2327,                   Dice: 87.39, HD: 7.40\nEpoch: [53/100], Batch: [50/63], Loss: 0.1942,                   Dice: 87.59, HD: 7.67\n\nEpoch: [53/100], Avg Loss: 0.330,               Train Dice: 87.22, Train HD: 7.98, Time : 26 sec\nAdjusting learning rate of group 0 to 4.5295e-04.\n\n\nEpoch: [54/100], Batch: [25/63], Loss: 0.4132,                   Dice: 85.41, HD: 7.96\nEpoch: [54/100], Batch: [50/63], Loss: 0.3963,                   Dice: 84.66, HD: 9.34\n\nEpoch: [54/100], Avg Loss: 0.345,               Train Dice: 84.85, Train HD: 9.30, Time : 30 sec\nAdjusting learning rate of group 0 to 4.3733e-04.\n\n\nEpoch: [55/100], Batch: [25/63], Loss: 0.4277,                   Dice: 88.71, HD: 6.36\nEpoch: [55/100], Batch: [50/63], Loss: 0.4390,                   Dice: 86.33, HD: 7.71\n\nEpoch: [55/100], Avg Loss: 0.354,               Train Dice: 85.63, Train HD: 8.04, Time : 28 sec\nAdjusting learning rate of group 0 to 4.2178e-04.\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : PROMISE12, Test Avg Dice : 73.89, Test Avg HD : 17.69, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : ISBI, Test Avg Dice : 74.81, Test Avg HD : 19.73, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [56/100], Batch: [25/63], Loss: 0.3498,                   Dice: 86.90, HD: 8.11\nEpoch: [56/100], Batch: [50/63], Loss: 0.4461,                   Dice: 85.96, HD: 7.87\n\nEpoch: [56/100], Avg Loss: 0.327,               Train Dice: 86.30, Train HD: 7.43, Time : 29 sec\nAdjusting learning rate of group 0 to 4.0631e-04.\n\n\nEpoch: [57/100], Batch: [25/63], Loss: 0.3493,                   Dice: 86.34, HD: 8.52\nEpoch: [57/100], Batch: [50/63], Loss: 0.4109,                   Dice: 85.65, HD: 8.26\n\nEpoch: [57/100], Avg Loss: 0.350,               Train Dice: 85.42, Train HD: 8.20, Time : 30 sec\nAdjusting learning rate of group 0 to 3.9093e-04.\n\n\nEpoch: [58/100], Batch: [25/63], Loss: 0.3318,                   Dice: 86.39, HD: 8.16\nEpoch: [58/100], Batch: [50/63], Loss: 0.4114,                   Dice: 85.48, HD: 8.11\n\nEpoch: [58/100], Avg Loss: 0.344,               Train Dice: 85.61, Train HD: 7.86, Time : 30 sec\nAdjusting learning rate of group 0 to 3.7566e-04.\n\n\nEpoch: [59/100], Batch: [25/63], Loss: 0.3991,                   Dice: 89.82, HD: 7.27\nEpoch: [59/100], Batch: [50/63], Loss: 0.4464,                   Dice: 87.36, HD: 7.73\n\nEpoch: [59/100], Avg Loss: 0.335,               Train Dice: 87.05, Train HD: 7.72, Time : 28 sec\nAdjusting learning rate of group 0 to 3.6050e-04.\n\n\nEpoch: [60/100], Batch: [25/63], Loss: 0.4370,                   Dice: 86.64, HD: 8.01\nEpoch: [60/100], Batch: [50/63], Loss: 0.2272,                   Dice: 86.33, HD: 7.98\n\nEpoch: [60/100], Avg Loss: 0.349,               Train Dice: 86.85, Train HD: 7.99, Time : 27 sec\nAdjusting learning rate of group 0 to 3.4549e-04.\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : PROMISE12, Test Avg Dice : 76.40, Test Avg HD : 15.54, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : ISBI, Test Avg Dice : 78.80, Test Avg HD : 17.88, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [61/100], Batch: [25/63], Loss: 0.4842,                   Dice: 83.73, HD: 8.18\nEpoch: [61/100], Batch: [50/63], Loss: 0.2632,                   Dice: 85.32, HD: 7.46\n\nEpoch: [61/100], Avg Loss: 0.349,               Train Dice: 84.94, Train HD: 7.70, Time : 28 sec\nAdjusting learning rate of group 0 to 3.3063e-04.\n\n\nEpoch: [62/100], Batch: [25/63], Loss: 0.4013,                   Dice: 84.67, HD: 7.93\nEpoch: [62/100], Batch: [50/63], Loss: 0.2812,                   Dice: 87.25, HD: 7.39\n\nEpoch: [62/100], Avg Loss: 0.342,               Train Dice: 86.95, Train HD: 7.94, Time : 28 sec\nAdjusting learning rate of group 0 to 3.1594e-04.\n\n\nEpoch: [63/100], Batch: [25/63], Loss: 0.2303,                   Dice: 86.03, HD: 7.29\nEpoch: [63/100], Batch: [50/63], Loss: 0.4382,                   Dice: 85.48, HD: 8.02\n\nEpoch: [63/100], Avg Loss: 0.348,               Train Dice: 86.07, Train HD: 7.78, Time : 28 sec\nAdjusting learning rate of group 0 to 3.0143e-04.\n\n\nEpoch: [64/100], Batch: [25/63], Loss: 0.1436,                   Dice: 85.90, HD: 7.87\nEpoch: [64/100], Batch: [50/63], Loss: 0.3316,                   Dice: 86.66, HD: 7.38\n\nEpoch: [64/100], Avg Loss: 0.352,               Train Dice: 86.48, Train HD: 7.54, Time : 29 sec\nAdjusting learning rate of group 0 to 2.8711e-04.\n\n\nEpoch: [65/100], Batch: [25/63], Loss: 0.3325,                   Dice: 87.70, HD: 7.19\nEpoch: [65/100], Batch: [50/63], Loss: 0.3790,                   Dice: 87.41, HD: 7.14\n\nEpoch: [65/100], Avg Loss: 0.342,               Train Dice: 87.30, Train HD: 7.25, Time : 27 sec\nAdjusting learning rate of group 0 to 2.7300e-04.\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : PROMISE12, Test Avg Dice : 77.90, Test Avg HD : 19.12, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : ISBI, Test Avg Dice : 78.26, Test Avg HD : 17.75, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [66/100], Batch: [25/63], Loss: 0.2924,                   Dice: 89.76, HD: 6.05\nEpoch: [66/100], Batch: [50/63], Loss: 0.3906,                   Dice: 88.97, HD: 6.88\n\nEpoch: [66/100], Avg Loss: 0.338,               Train Dice: 88.74, Train HD: 7.13, Time : 27 sec\nAdjusting learning rate of group 0 to 2.5912e-04.\n\n\nEpoch: [67/100], Batch: [25/63], Loss: 0.2702,                   Dice: 88.93, HD: 5.61\nEpoch: [67/100], Batch: [50/63], Loss: 0.3325,                   Dice: 88.10, HD: 6.95\n\nEpoch: [67/100], Avg Loss: 0.323,               Train Dice: 88.05, Train HD: 7.05, Time : 28 sec\nAdjusting learning rate of group 0 to 2.4548e-04.\n\n\nEpoch: [68/100], Batch: [25/63], Loss: 0.3914,                   Dice: 87.02, HD: 7.33\nEpoch: [68/100], Batch: [50/63], Loss: 0.2569,                   Dice: 87.54, HD: 7.35\n\nEpoch: [68/100], Avg Loss: 0.339,               Train Dice: 88.05, Train HD: 7.04, Time : 28 sec\nAdjusting learning rate of group 0 to 2.3209e-04.\n\n\nEpoch: [69/100], Batch: [25/63], Loss: 0.3205,                   Dice: 90.01, HD: 5.49\nEpoch: [69/100], Batch: [50/63], Loss: 0.3854,                   Dice: 89.56, HD: 6.35\n\nEpoch: [69/100], Avg Loss: 0.334,               Train Dice: 88.96, Train HD: 6.63, Time : 28 sec\nAdjusting learning rate of group 0 to 2.1896e-04.\n\n\nEpoch: [70/100], Batch: [25/63], Loss: 0.3437,                   Dice: 88.93, HD: 6.55\nEpoch: [70/100], Batch: [50/63], Loss: 0.1623,                   Dice: 89.48, HD: 6.38\n\nEpoch: [70/100], Avg Loss: 0.330,               Train Dice: 88.52, Train HD: 6.58, Time : 26 sec\nAdjusting learning rate of group 0 to 2.0611e-04.\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : PROMISE12, Test Avg Dice : 77.23, Test Avg HD : 16.20, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : ISBI, Test Avg Dice : 77.55, Test Avg HD : 16.79, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [71/100], Batch: [25/63], Loss: 0.4517,                   Dice: 86.59, HD: 7.13\nEpoch: [71/100], Batch: [50/63], Loss: 0.2880,                   Dice: 87.34, HD: 7.49\n\nEpoch: [71/100], Avg Loss: 0.344,               Train Dice: 87.35, Train HD: 7.15, Time : 30 sec\nAdjusting learning rate of group 0 to 1.9355e-04.\n\n\nEpoch: [72/100], Batch: [25/63], Loss: 0.4822,                   Dice: 87.43, HD: 7.29\nEpoch: [72/100], Batch: [50/63], Loss: 0.4485,                   Dice: 88.71, HD: 6.76\n\nEpoch: [72/100], Avg Loss: 0.341,               Train Dice: 88.79, Train HD: 6.56, Time : 29 sec\nAdjusting learning rate of group 0 to 1.8129e-04.\n\n\nEpoch: [73/100], Batch: [25/63], Loss: 0.2055,                   Dice: 89.59, HD: 6.00\nEpoch: [73/100], Batch: [50/63], Loss: 0.2491,                   Dice: 89.11, HD: 6.95\n\nEpoch: [73/100], Avg Loss: 0.329,               Train Dice: 89.56, Train HD: 6.65, Time : 28 sec\nAdjusting learning rate of group 0 to 1.6934e-04.\n\n\nEpoch: [74/100], Batch: [25/63], Loss: 0.4291,                   Dice: 90.00, HD: 6.46\nEpoch: [74/100], Batch: [50/63], Loss: 0.3440,                   Dice: 87.47, HD: 7.21\n\nEpoch: [74/100], Avg Loss: 0.349,               Train Dice: 87.77, Train HD: 7.21, Time : 31 sec\nAdjusting learning rate of group 0 to 1.5773e-04.\n\n\nEpoch: [75/100], Batch: [25/63], Loss: 0.2982,                   Dice: 87.55, HD: 7.33\nEpoch: [75/100], Batch: [50/63], Loss: 0.3677,                   Dice: 88.70, HD: 6.75\n\nEpoch: [75/100], Avg Loss: 0.333,               Train Dice: 88.86, Train HD: 6.55, Time : 27 sec\nAdjusting learning rate of group 0 to 1.4645e-04.\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : PROMISE12, Test Avg Dice : 78.33, Test Avg HD : 15.23, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : ISBI, Test Avg Dice : 77.93, Test Avg HD : 16.99, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [76/100], Batch: [25/63], Loss: 0.3258,                   Dice: 87.56, HD: 6.88\nEpoch: [76/100], Batch: [50/63], Loss: 0.4086,                   Dice: 87.16, HD: 7.04\n\nEpoch: [76/100], Avg Loss: 0.335,               Train Dice: 87.50, Train HD: 6.96, Time : 26 sec\nAdjusting learning rate of group 0 to 1.3552e-04.\n\n\nEpoch: [77/100], Batch: [25/63], Loss: 0.3101,                   Dice: 91.64, HD: 5.64\nEpoch: [77/100], Batch: [50/63], Loss: 0.4498,                   Dice: 89.82, HD: 6.26\n\nEpoch: [77/100], Avg Loss: 0.330,               Train Dice: 89.52, Train HD: 6.43, Time : 29 sec\nAdjusting learning rate of group 0 to 1.2494e-04.\n\n\nEpoch: [78/100], Batch: [25/63], Loss: 0.2347,                   Dice: 88.23, HD: 5.67\nEpoch: [78/100], Batch: [50/63], Loss: 0.3356,                   Dice: 88.95, HD: 5.79\n\nEpoch: [78/100], Avg Loss: 0.325,               Train Dice: 89.19, Train HD: 5.93, Time : 26 sec\nAdjusting learning rate of group 0 to 1.1474e-04.\n\n\nEpoch: [79/100], Batch: [25/63], Loss: 0.4216,                   Dice: 88.41, HD: 6.63\nEpoch: [79/100], Batch: [50/63], Loss: 0.3168,                   Dice: 88.30, HD: 6.25\n\nEpoch: [79/100], Avg Loss: 0.326,               Train Dice: 88.74, Train HD: 6.26, Time : 27 sec\nAdjusting learning rate of group 0 to 1.0492e-04.\n\n\nEpoch: [80/100], Batch: [25/63], Loss: 0.2231,                   Dice: 90.68, HD: 5.82\nEpoch: [80/100], Batch: [50/63], Loss: 0.4124,                   Dice: 89.38, HD: 6.41\n\nEpoch: [80/100], Avg Loss: 0.328,               Train Dice: 88.92, Train HD: 6.52, Time : 27 sec\nAdjusting learning rate of group 0 to 9.5492e-05.\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : PROMISE12, Test Avg Dice : 76.45, Test Avg HD : 15.86, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : ISBI, Test Avg Dice : 78.35, Test Avg HD : 16.32, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [81/100], Batch: [25/63], Loss: 0.3537,                   Dice: 89.23, HD: 6.48\nEpoch: [81/100], Batch: [50/63], Loss: 0.3178,                   Dice: 88.04, HD: 6.78\n\nEpoch: [81/100], Avg Loss: 0.346,               Train Dice: 88.11, Train HD: 6.73, Time : 30 sec\nAdjusting learning rate of group 0 to 8.6460e-05.\n\n\nEpoch: [82/100], Batch: [25/63], Loss: 0.3004,                   Dice: 88.50, HD: 6.53\nEpoch: [82/100], Batch: [50/63], Loss: 0.5007,                   Dice: 88.49, HD: 6.52\n\nEpoch: [82/100], Avg Loss: 0.347,               Train Dice: 88.49, Train HD: 6.36, Time : 31 sec\nAdjusting learning rate of group 0 to 7.7836e-05.\n\n\nEpoch: [83/100], Batch: [25/63], Loss: 0.3298,                   Dice: 91.06, HD: 6.17\nEpoch: [83/100], Batch: [50/63], Loss: 0.2103,                   Dice: 90.17, HD: 6.52\n\nEpoch: [83/100], Avg Loss: 0.325,               Train Dice: 90.70, Train HD: 6.18, Time : 27 sec\nAdjusting learning rate of group 0 to 6.9629e-05.\n\n\nEpoch: [84/100], Batch: [25/63], Loss: 0.3035,                   Dice: 89.94, HD: 5.60\nEpoch: [84/100], Batch: [50/63], Loss: 0.3179,                   Dice: 89.34, HD: 6.03\n\nEpoch: [84/100], Avg Loss: 0.326,               Train Dice: 89.08, Train HD: 6.01, Time : 30 sec\nAdjusting learning rate of group 0 to 6.1847e-05.\n\n\nEpoch: [85/100], Batch: [25/63], Loss: 0.3454,                   Dice: 89.08, HD: 6.29\nEpoch: [85/100], Batch: [50/63], Loss: 0.1715,                   Dice: 89.07, HD: 6.90\n\nEpoch: [85/100], Avg Loss: 0.335,               Train Dice: 88.69, Train HD: 6.79, Time : 29 sec\nAdjusting learning rate of group 0 to 5.4497e-05.\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : PROMISE12, Test Avg Dice : 77.33, Test Avg HD : 19.02, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : ISBI, Test Avg Dice : 78.38, Test Avg HD : 16.44, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [86/100], Batch: [25/63], Loss: 0.3291,                   Dice: 86.46, HD: 7.95\nEpoch: [86/100], Batch: [50/63], Loss: 0.3146,                   Dice: 89.09, HD: 6.55\n\nEpoch: [86/100], Avg Loss: 0.325,               Train Dice: 89.02, Train HD: 6.33, Time : 28 sec\nAdjusting learning rate of group 0 to 4.7586e-05.\n\n\nEpoch: [87/100], Batch: [25/63], Loss: 0.3459,                   Dice: 90.42, HD: 6.04\nEpoch: [87/100], Batch: [50/63], Loss: 0.3075,                   Dice: 89.47, HD: 5.93\n\nEpoch: [87/100], Avg Loss: 0.330,               Train Dice: 89.19, Train HD: 6.03, Time : 30 sec\nAdjusting learning rate of group 0 to 4.1123e-05.\n\n\nEpoch: [88/100], Batch: [25/63], Loss: 0.3327,                   Dice: 89.56, HD: 6.37\nEpoch: [88/100], Batch: [50/63], Loss: 0.2113,                   Dice: 89.63, HD: 6.23\n\nEpoch: [88/100], Avg Loss: 0.325,               Train Dice: 89.44, Train HD: 6.19, Time : 28 sec\nAdjusting learning rate of group 0 to 3.5112e-05.\n\n\nEpoch: [89/100], Batch: [25/63], Loss: 0.3444,                   Dice: 91.10, HD: 5.33\nEpoch: [89/100], Batch: [50/63], Loss: 0.2908,                   Dice: 90.90, HD: 6.06\n\nEpoch: [89/100], Avg Loss: 0.325,               Train Dice: 90.96, Train HD: 6.08, Time : 28 sec\nAdjusting learning rate of group 0 to 2.9560e-05.\n\n\nEpoch: [90/100], Batch: [25/63], Loss: 0.3491,                   Dice: 90.84, HD: 7.15\nEpoch: [90/100], Batch: [50/63], Loss: 0.4162,                   Dice: 89.91, HD: 6.36\n\nEpoch: [90/100], Avg Loss: 0.328,               Train Dice: 88.77, Train HD: 6.54, Time : 31 sec\nAdjusting learning rate of group 0 to 2.4472e-05.\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : PROMISE12, Test Avg Dice : 75.84, Test Avg HD : 19.75, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : ISBI, Test Avg Dice : 77.72, Test Avg HD : 16.96, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [91/100], Batch: [25/63], Loss: 0.3366,                   Dice: 87.36, HD: 7.32\nEpoch: [91/100], Batch: [50/63], Loss: 0.3063,                   Dice: 89.24, HD: 6.28\n\nEpoch: [91/100], Avg Loss: 0.336,               Train Dice: 88.61, Train HD: 6.18, Time : 28 sec\nAdjusting learning rate of group 0 to 1.9853e-05.\n\n\nEpoch: [92/100], Batch: [25/63], Loss: 0.2501,                   Dice: 90.11, HD: 6.22\nEpoch: [92/100], Batch: [50/63], Loss: 0.1906,                   Dice: 90.32, HD: 5.95\n\nEpoch: [92/100], Avg Loss: 0.316,               Train Dice: 90.14, Train HD: 5.96, Time : 26 sec\nAdjusting learning rate of group 0 to 1.5708e-05.\n\n\nEpoch: [93/100], Batch: [25/63], Loss: 0.3158,                   Dice: 86.03, HD: 6.42\nEpoch: [93/100], Batch: [50/63], Loss: 0.2997,                   Dice: 88.56, HD: 5.90\n\nEpoch: [93/100], Avg Loss: 0.337,               Train Dice: 87.49, Train HD: 6.60, Time : 29 sec\nAdjusting learning rate of group 0 to 1.2042e-05.\n\n\nEpoch: [94/100], Batch: [25/63], Loss: 0.3517,                   Dice: 88.21, HD: 6.70\nEpoch: [94/100], Batch: [50/63], Loss: 0.2358,                   Dice: 87.95, HD: 6.50\n\nEpoch: [94/100], Avg Loss: 0.338,               Train Dice: 88.44, Train HD: 6.38, Time : 28 sec\nAdjusting learning rate of group 0 to 8.8564e-06.\n\n\nEpoch: [95/100], Batch: [25/63], Loss: 0.3833,                   Dice: 88.72, HD: 5.94\nEpoch: [95/100], Batch: [50/63], Loss: 0.2192,                   Dice: 89.25, HD: 6.40\n\nEpoch: [95/100], Avg Loss: 0.334,               Train Dice: 89.25, Train HD: 6.45, Time : 30 sec\nAdjusting learning rate of group 0 to 6.1558e-06.\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : PROMISE12, Test Avg Dice : 75.11, Test Avg HD : 16.71, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : ISBI, Test Avg Dice : 77.24, Test Avg HD : 17.40, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [96/100], Batch: [25/63], Loss: 0.4467,                   Dice: 88.80, HD: 6.46\nEpoch: [96/100], Batch: [50/63], Loss: 0.2920,                   Dice: 90.60, HD: 6.06\n\nEpoch: [96/100], Avg Loss: 0.328,               Train Dice: 89.75, Train HD: 6.48, Time : 28 sec\nAdjusting learning rate of group 0 to 3.9426e-06.\n\n\nEpoch: [97/100], Batch: [25/63], Loss: 0.2585,                   Dice: 89.73, HD: 6.05\nEpoch: [97/100], Batch: [50/63], Loss: 0.4157,                   Dice: 89.98, HD: 6.16\n\nEpoch: [97/100], Avg Loss: 0.336,               Train Dice: 89.55, Train HD: 6.05, Time : 31 sec\nAdjusting learning rate of group 0 to 2.2190e-06.\n\n\nEpoch: [98/100], Batch: [25/63], Loss: 0.3017,                   Dice: 91.21, HD: 4.95\nEpoch: [98/100], Batch: [50/63], Loss: 0.2685,                   Dice: 90.35, HD: 5.75\n\nEpoch: [98/100], Avg Loss: 0.322,               Train Dice: 90.29, Train HD: 5.72, Time : 29 sec\nAdjusting learning rate of group 0 to 9.8664e-07.\n\n\nEpoch: [99/100], Batch: [25/63], Loss: 0.3308,                   Dice: 90.76, HD: 6.00\nEpoch: [99/100], Batch: [50/63], Loss: 0.2985,                   Dice: 90.27, HD: 5.67\n\nEpoch: [99/100], Avg Loss: 0.322,               Train Dice: 90.35, Train HD: 5.75, Time : 27 sec\nAdjusting learning rate of group 0 to 2.4672e-07.\n\n\nEpoch: [100/100], Batch: [25/63], Loss: 0.2196,                   Dice: 89.50, HD: 6.10\nEpoch: [100/100], Batch: [50/63], Loss: 0.4081,                   Dice: 89.26, HD: 6.01\n\nEpoch: [100/100], Avg Loss: 0.330,               Train Dice: 89.31, Train HD: 5.79, Time : 27 sec\nAdjusting learning rate of group 0 to 0.0000e+00.\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : PROMISE12, Test Avg Dice : 74.03, Test Avg HD : 17.32, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : ISBI, Test Avg Dice : 76.72, Test Avg HD : 17.83, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Store few samples to replay memory buffer","metadata":{}},{"cell_type":"code","source":"replay_percentage = 0.1\ntrain_samples_count = len(dataset_map[dataset_name]['train']['images'])\nreplay_count = int(train_samples_count * replay_percentage)\nprint(f\"Storing {replay_count} ISBI Samples to replay buffer\")\nidxs = idxs = list(map(int, np.linspace(0, train_samples_count-1, num=replay_count).tolist()))\nreplay_buffer['train']['images'] +=  [dataset_map[dataset_name]['train']['images'][idx] for idx in idxs]\nreplay_buffer['train']['labels'] +=  [dataset_map[dataset_name]['train']['labels'][idx] for idx in idxs]\nprint(f\"Current replay buffer size : {len(replay_buffer['train']['labels'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-10T09:36:49.850213Z","iopub.execute_input":"2022-09-10T09:36:49.850586Z","iopub.status.idle":"2022-09-10T09:36:49.859377Z","shell.execute_reply.started":"2022-09-10T09:36:49.850550Z","shell.execute_reply":"2022-09-10T09:36:49.858266Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Storing 6 ISBI Samples to replay buffer\nCurrent replay buffer size : 10\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Train on Decathlon --> Test on Promise12, ISBI & Decathlon\nepochs = 100\ninitial_lr = 1e-3\noptimizer = Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n# optimizer = ASGD(model.parameters(), lr=initial_lr)\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=True)\n\n\ndataset_name = 'isbi'\n# img_paths = dataset_map[dataset_name]['train']['images'] + replay_buffer['train']['images']\n# label_paths = dataset_map[dataset_name]['train']['labels'] + replay_buffer['train']['labels']\n\nimg_paths = dataset_map[dataset_name]['train']['images'] \nlabel_paths = dataset_map[dataset_name]['train']['labels'] \n\ntrain_loader = get_dataloader(img_paths = img_paths,\n                           label_paths = label_paths,\n                           train = True)\n\nem_loader = get_dataloader(img_paths = replay_buffer['train']['images'],\n                              label_paths = replay_buffer['train']['labels'],\n                              train = True)\n\ntest_dataset_names = ['promise12', 'isbi', 'decathlon']\n\nmetric_prefix  += 'dec->'\n\nmetrics_map = {}\nfor dname in test_dataset_names:\n    metrics_map[dname] = {\n        f'{metric_prefix}_{dname}_curr_dice' : 0,\n        f'{metric_prefix}_{dname}_best_dice' : 0,\n        f'{metric_prefix}_{dname}_curr_hd' : 1e10,\n        f'{metric_prefix}_{dname}_best_hd' : 1e10,\n        'Epoch' : 0\n    }\n\nfor epoch in range(1, epochs+1):   \n    \n        train(train_loader)\n        \n        if epoch % val_interval == 0:\n            for dname in test_dataset_names:\n                val_dice, val_hd = validate(test_loader = dataloaders_map[dname]['test'], dataset_name = dname)\n\n                val_dice *= 100\n\n                metrics = metrics_map[dname]\n\n                metrics[f'Epoch'] = epoch\n                metrics[f'{metric_prefix}_{dname}_curr_dice'] = val_dice \n                metrics[f'{metric_prefix}_{dname}_curr_hd'] = val_hd\n                metrics[f'{metric_prefix}_{dname}_best_dice'] = max(val_dice, metrics[f'{metric_prefix}_{dname}_best_dice'])\n\n                if val_hd < metrics[f'{metric_prefix}_{dname}_best_hd'] and val_hd > 0:\n                    metrics[f'{metric_prefix}_{dname}_best_hd'] = val_hd\n\n                if wandb_log:\n                    # Quantiative metrics\n                    wandb.log(metrics)\n                    print('Logged data to wandb')","metadata":{"execution":{"iopub.status.busy":"2022-09-10T09:36:49.861053Z","iopub.execute_input":"2022-09-10T09:36:49.861425Z","iopub.status.idle":"2022-09-10T10:05:14.277255Z","shell.execute_reply.started":"2022-09-10T09:36:49.861390Z","shell.execute_reply":"2022-09-10T10:05:14.276260Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0000e-03.\n\n\nEpoch: [1/100], Batch: [25/63], Loss: 0.2645,                   Dice: 80.90, HD: 15.08\nEpoch: [1/100], Batch: [50/63], Loss: 0.3405,                   Dice: 77.67, HD: 17.06\n\nEpoch: [1/100], Avg Loss: 0.357,               Train Dice: 79.19, Train HD: 15.86, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9975e-04.\n\n\nEpoch: [2/100], Batch: [25/63], Loss: 0.3937,                   Dice: 81.40, HD: 11.62\nEpoch: [2/100], Batch: [50/63], Loss: 0.3842,                   Dice: 80.69, HD: 13.08\n\nEpoch: [2/100], Avg Loss: 0.374,               Train Dice: 79.37, Train HD: 15.09, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9901e-04.\n\n\nEpoch: [3/100], Batch: [25/63], Loss: 0.4959,                   Dice: 73.53, HD: 19.03\nEpoch: [3/100], Batch: [50/63], Loss: 0.4530,                   Dice: 76.28, HD: 16.59\n\nEpoch: [3/100], Avg Loss: 0.383,               Train Dice: 78.24, Train HD: 15.34, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9778e-04.\n\n\nEpoch: [4/100], Batch: [25/63], Loss: 0.4626,                   Dice: 76.83, HD: 11.66\nEpoch: [4/100], Batch: [50/63], Loss: 0.4259,                   Dice: 79.66, HD: 12.11\n\nEpoch: [4/100], Avg Loss: 0.357,               Train Dice: 80.41, Train HD: 12.08, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9606e-04.\n\n\nEpoch: [5/100], Batch: [25/63], Loss: 0.4381,                   Dice: 84.95, HD: 9.50\nEpoch: [5/100], Batch: [50/63], Loss: 0.2526,                   Dice: 82.97, HD: 10.31\n\nEpoch: [5/100], Avg Loss: 0.340,               Train Dice: 82.63, Train HD: 10.44, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9384e-04.\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : PROMISE12, Test Avg Dice : 77.76, Test Avg HD : 24.25, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : ISBI, Test Avg Dice : 78.95, Test Avg HD : 17.56, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [5/100], Dataset : DECATHLON, Test Avg Dice : 85.01, Test Avg HD : 10.61, Time : 4 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [6/100], Batch: [25/63], Loss: 0.3773,                   Dice: 81.41, HD: 12.92\nEpoch: [6/100], Batch: [50/63], Loss: 0.1814,                   Dice: 82.38, HD: 12.33\n\nEpoch: [6/100], Avg Loss: 0.354,               Train Dice: 82.20, Train HD: 13.12, Time : 12 sec\nAdjusting learning rate of group 0 to 9.9114e-04.\n\n\nEpoch: [7/100], Batch: [25/63], Loss: 0.2876,                   Dice: 81.14, HD: 11.13\nEpoch: [7/100], Batch: [50/63], Loss: 0.4304,                   Dice: 81.82, HD: 11.96\n\nEpoch: [7/100], Avg Loss: 0.344,               Train Dice: 80.75, Train HD: 12.06, Time : 12 sec\nAdjusting learning rate of group 0 to 9.8796e-04.\n\n\nEpoch: [8/100], Batch: [25/63], Loss: 0.3065,                   Dice: 75.83, HD: 19.74\nEpoch: [8/100], Batch: [50/63], Loss: 0.5065,                   Dice: 72.35, HD: 20.47\n\nEpoch: [8/100], Avg Loss: 0.433,               Train Dice: 72.23, Train HD: 19.55, Time : 12 sec\nAdjusting learning rate of group 0 to 9.8429e-04.\n\n\nEpoch: [9/100], Batch: [25/63], Loss: 0.3509,                   Dice: 79.74, HD: 15.13\nEpoch: [9/100], Batch: [50/63], Loss: 0.3377,                   Dice: 80.07, HD: 14.55\n\nEpoch: [9/100], Avg Loss: 0.363,               Train Dice: 79.56, Train HD: 13.96, Time : 12 sec\nAdjusting learning rate of group 0 to 9.8015e-04.\n\n\nEpoch: [10/100], Batch: [25/63], Loss: 0.2534,                   Dice: 78.09, HD: 13.86\nEpoch: [10/100], Batch: [50/63], Loss: 0.2298,                   Dice: 76.26, HD: 14.57\n\nEpoch: [10/100], Avg Loss: 0.360,               Train Dice: 77.30, Train HD: 13.64, Time : 12 sec\nAdjusting learning rate of group 0 to 9.7553e-04.\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : PROMISE12, Test Avg Dice : 78.31, Test Avg HD : 21.08, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : ISBI, Test Avg Dice : 76.70, Test Avg HD : 20.18, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [10/100], Dataset : DECATHLON, Test Avg Dice : 82.07, Test Avg HD : 14.79, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [11/100], Batch: [25/63], Loss: 0.1615,                   Dice: 82.23, HD: 12.17\nEpoch: [11/100], Batch: [50/63], Loss: 0.4344,                   Dice: 81.00, HD: 11.50\n\nEpoch: [11/100], Avg Loss: 0.343,               Train Dice: 81.24, Train HD: 11.90, Time : 12 sec\nAdjusting learning rate of group 0 to 9.7044e-04.\n\n\nEpoch: [12/100], Batch: [25/63], Loss: 0.3920,                   Dice: 81.29, HD: 13.64\nEpoch: [12/100], Batch: [50/63], Loss: 0.1766,                   Dice: 82.48, HD: 12.00\n\nEpoch: [12/100], Avg Loss: 0.347,               Train Dice: 81.47, Train HD: 11.70, Time : 12 sec\nAdjusting learning rate of group 0 to 9.6489e-04.\n\n\nEpoch: [13/100], Batch: [25/63], Loss: 0.3109,                   Dice: 81.15, HD: 12.77\nEpoch: [13/100], Batch: [50/63], Loss: 0.2788,                   Dice: 81.54, HD: 12.71\n\nEpoch: [13/100], Avg Loss: 0.342,               Train Dice: 83.21, Train HD: 11.65, Time : 12 sec\nAdjusting learning rate of group 0 to 9.5888e-04.\n\n\nEpoch: [14/100], Batch: [25/63], Loss: 0.3157,                   Dice: 84.63, HD: 10.88\nEpoch: [14/100], Batch: [50/63], Loss: 0.4668,                   Dice: 82.85, HD: 11.33\n\nEpoch: [14/100], Avg Loss: 0.337,               Train Dice: 82.96, Train HD: 11.27, Time : 12 sec\nAdjusting learning rate of group 0 to 9.5241e-04.\n\n\nEpoch: [15/100], Batch: [25/63], Loss: 0.4598,                   Dice: 79.11, HD: 12.03\nEpoch: [15/100], Batch: [50/63], Loss: 0.2225,                   Dice: 79.65, HD: 14.05\n\nEpoch: [15/100], Avg Loss: 0.353,               Train Dice: 79.85, Train HD: 14.50, Time : 12 sec\nAdjusting learning rate of group 0 to 9.4550e-04.\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : PROMISE12, Test Avg Dice : 76.56, Test Avg HD : 24.88, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : ISBI, Test Avg Dice : 79.62, Test Avg HD : 23.49, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [15/100], Dataset : DECATHLON, Test Avg Dice : 80.61, Test Avg HD : 26.94, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [16/100], Batch: [25/63], Loss: 0.2656,                   Dice: 79.84, HD: 14.77\nEpoch: [16/100], Batch: [50/63], Loss: 0.2257,                   Dice: 81.58, HD: 14.08\n\nEpoch: [16/100], Avg Loss: 0.365,               Train Dice: 81.01, Train HD: 14.08, Time : 13 sec\nAdjusting learning rate of group 0 to 9.3815e-04.\n\n\nEpoch: [17/100], Batch: [25/63], Loss: 0.3707,                   Dice: 81.49, HD: 10.48\nEpoch: [17/100], Batch: [50/63], Loss: 0.3571,                   Dice: 82.29, HD: 10.48\n\nEpoch: [17/100], Avg Loss: 0.350,               Train Dice: 81.27, Train HD: 10.93, Time : 12 sec\nAdjusting learning rate of group 0 to 9.3037e-04.\n\n\nEpoch: [18/100], Batch: [25/63], Loss: 0.5507,                   Dice: 80.53, HD: 14.48\nEpoch: [18/100], Batch: [50/63], Loss: 0.2422,                   Dice: 83.50, HD: 11.92\n\nEpoch: [18/100], Avg Loss: 0.347,               Train Dice: 82.94, Train HD: 11.67, Time : 12 sec\nAdjusting learning rate of group 0 to 9.2216e-04.\n\n\nEpoch: [19/100], Batch: [25/63], Loss: 0.4153,                   Dice: 81.84, HD: 13.28\nEpoch: [19/100], Batch: [50/63], Loss: 0.3315,                   Dice: 84.53, HD: 10.90\n\nEpoch: [19/100], Avg Loss: 0.340,               Train Dice: 85.17, Train HD: 10.79, Time : 12 sec\nAdjusting learning rate of group 0 to 9.1354e-04.\n\n\nEpoch: [20/100], Batch: [25/63], Loss: 0.2336,                   Dice: 83.42, HD: 10.77\nEpoch: [20/100], Batch: [50/63], Loss: 0.1888,                   Dice: 84.72, HD: 9.71\n\nEpoch: [20/100], Avg Loss: 0.337,               Train Dice: 82.72, Train HD: 10.37, Time : 12 sec\nAdjusting learning rate of group 0 to 9.0451e-04.\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : PROMISE12, Test Avg Dice : 78.69, Test Avg HD : 23.84, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : ISBI, Test Avg Dice : 78.29, Test Avg HD : 18.13, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [20/100], Dataset : DECATHLON, Test Avg Dice : 84.33, Test Avg HD : 14.52, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [21/100], Batch: [25/63], Loss: 0.0979,                   Dice: 83.69, HD: 9.66\nEpoch: [21/100], Batch: [50/63], Loss: 0.4518,                   Dice: 83.67, HD: 10.21\n\nEpoch: [21/100], Avg Loss: 0.339,               Train Dice: 83.68, Train HD: 10.04, Time : 12 sec\nAdjusting learning rate of group 0 to 8.9508e-04.\n\n\nEpoch: [22/100], Batch: [25/63], Loss: 0.4240,                   Dice: 81.16, HD: 11.27\nEpoch: [22/100], Batch: [50/63], Loss: 0.3150,                   Dice: 83.71, HD: 10.20\n\nEpoch: [22/100], Avg Loss: 0.330,               Train Dice: 84.70, Train HD: 10.03, Time : 13 sec\nAdjusting learning rate of group 0 to 8.8526e-04.\n\n\nEpoch: [23/100], Batch: [25/63], Loss: 0.3052,                   Dice: 88.39, HD: 7.97\nEpoch: [23/100], Batch: [50/63], Loss: 0.1971,                   Dice: 84.85, HD: 9.41\n\nEpoch: [23/100], Avg Loss: 0.333,               Train Dice: 83.90, Train HD: 10.26, Time : 12 sec\nAdjusting learning rate of group 0 to 8.7506e-04.\n\n\nEpoch: [24/100], Batch: [25/63], Loss: 0.3544,                   Dice: 83.53, HD: 10.15\nEpoch: [24/100], Batch: [50/63], Loss: 0.3984,                   Dice: 84.03, HD: 10.05\n\nEpoch: [24/100], Avg Loss: 0.343,               Train Dice: 83.04, Train HD: 10.71, Time : 12 sec\nAdjusting learning rate of group 0 to 8.6448e-04.\n\n\nEpoch: [25/100], Batch: [25/63], Loss: 0.3053,                   Dice: 86.88, HD: 8.69\nEpoch: [25/100], Batch: [50/63], Loss: 0.5188,                   Dice: 85.39, HD: 9.30\n\nEpoch: [25/100], Avg Loss: 0.345,               Train Dice: 84.28, Train HD: 10.13, Time : 12 sec\nAdjusting learning rate of group 0 to 8.5355e-04.\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : PROMISE12, Test Avg Dice : 70.22, Test Avg HD : 31.02, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : ISBI, Test Avg Dice : 79.15, Test Avg HD : 21.74, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [25/100], Dataset : DECATHLON, Test Avg Dice : 83.90, Test Avg HD : 14.00, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [26/100], Batch: [25/63], Loss: 0.4087,                   Dice: 79.89, HD: 13.56\nEpoch: [26/100], Batch: [50/63], Loss: 0.5417,                   Dice: 81.15, HD: 14.01\n\nEpoch: [26/100], Avg Loss: 0.349,               Train Dice: 80.77, Train HD: 13.20, Time : 12 sec\nAdjusting learning rate of group 0 to 8.4227e-04.\n\n\nEpoch: [27/100], Batch: [25/63], Loss: 0.2167,                   Dice: 79.88, HD: 11.42\nEpoch: [27/100], Batch: [50/63], Loss: 0.3720,                   Dice: 83.78, HD: 10.25\n\nEpoch: [27/100], Avg Loss: 0.335,               Train Dice: 83.94, Train HD: 10.16, Time : 12 sec\nAdjusting learning rate of group 0 to 8.3066e-04.\n\n\nEpoch: [28/100], Batch: [25/63], Loss: 0.3898,                   Dice: 79.35, HD: 11.22\nEpoch: [28/100], Batch: [50/63], Loss: 0.3347,                   Dice: 81.33, HD: 11.84\n\nEpoch: [28/100], Avg Loss: 0.358,               Train Dice: 82.35, Train HD: 12.28, Time : 12 sec\nAdjusting learning rate of group 0 to 8.1871e-04.\n\n\nEpoch: [29/100], Batch: [25/63], Loss: 0.4201,                   Dice: 82.85, HD: 13.15\nEpoch: [29/100], Batch: [50/63], Loss: 0.3600,                   Dice: 80.29, HD: 12.67\n\nEpoch: [29/100], Avg Loss: 0.347,               Train Dice: 81.40, Train HD: 12.05, Time : 12 sec\nAdjusting learning rate of group 0 to 8.0645e-04.\n\n\nEpoch: [30/100], Batch: [25/63], Loss: 0.3254,                   Dice: 85.88, HD: 9.76\nEpoch: [30/100], Batch: [50/63], Loss: 0.1813,                   Dice: 82.98, HD: 11.38\n\nEpoch: [30/100], Avg Loss: 0.344,               Train Dice: 82.63, Train HD: 11.42, Time : 12 sec\nAdjusting learning rate of group 0 to 7.9389e-04.\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : PROMISE12, Test Avg Dice : 66.78, Test Avg HD : 30.75, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : ISBI, Test Avg Dice : 76.25, Test Avg HD : 21.78, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [30/100], Dataset : DECATHLON, Test Avg Dice : 81.60, Test Avg HD : 18.12, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [31/100], Batch: [25/63], Loss: 0.3005,                   Dice: 78.25, HD: 15.87\nEpoch: [31/100], Batch: [50/63], Loss: 0.5350,                   Dice: 80.17, HD: 13.56\n\nEpoch: [31/100], Avg Loss: 0.351,               Train Dice: 80.10, Train HD: 13.29, Time : 12 sec\nAdjusting learning rate of group 0 to 7.8104e-04.\n\n\nEpoch: [32/100], Batch: [25/63], Loss: 0.1230,                   Dice: 85.45, HD: 10.18\nEpoch: [32/100], Batch: [50/63], Loss: 0.2400,                   Dice: 84.24, HD: 10.08\n\nEpoch: [32/100], Avg Loss: 0.340,               Train Dice: 83.92, Train HD: 9.91, Time : 12 sec\nAdjusting learning rate of group 0 to 7.6791e-04.\n\n\nEpoch: [33/100], Batch: [25/63], Loss: 0.3531,                   Dice: 85.84, HD: 9.17\nEpoch: [33/100], Batch: [50/63], Loss: 0.3469,                   Dice: 82.81, HD: 9.57\n\nEpoch: [33/100], Avg Loss: 0.328,               Train Dice: 83.02, Train HD: 10.16, Time : 12 sec\nAdjusting learning rate of group 0 to 7.5452e-04.\n\n\nEpoch: [34/100], Batch: [25/63], Loss: 0.1853,                   Dice: 81.86, HD: 11.25\nEpoch: [34/100], Batch: [50/63], Loss: 0.1706,                   Dice: 83.96, HD: 10.72\n\nEpoch: [34/100], Avg Loss: 0.330,               Train Dice: 84.13, Train HD: 10.85, Time : 12 sec\nAdjusting learning rate of group 0 to 7.4088e-04.\n\n\nEpoch: [35/100], Batch: [25/63], Loss: 0.3818,                   Dice: 84.55, HD: 9.33\nEpoch: [35/100], Batch: [50/63], Loss: 0.3543,                   Dice: 84.60, HD: 9.19\n\nEpoch: [35/100], Avg Loss: 0.321,               Train Dice: 85.09, Train HD: 9.35, Time : 12 sec\nAdjusting learning rate of group 0 to 7.2700e-04.\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : PROMISE12, Test Avg Dice : 68.52, Test Avg HD : 24.06, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : ISBI, Test Avg Dice : 78.60, Test Avg HD : 19.82, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [35/100], Dataset : DECATHLON, Test Avg Dice : 83.03, Test Avg HD : 14.64, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [36/100], Batch: [25/63], Loss: 0.3155,                   Dice: 84.70, HD: 9.27\nEpoch: [36/100], Batch: [50/63], Loss: 0.1935,                   Dice: 85.66, HD: 9.44\n\nEpoch: [36/100], Avg Loss: 0.317,               Train Dice: 86.26, Train HD: 8.97, Time : 12 sec\nAdjusting learning rate of group 0 to 7.1289e-04.\n\n\nEpoch: [37/100], Batch: [25/63], Loss: 0.3859,                   Dice: 88.04, HD: 8.52\nEpoch: [37/100], Batch: [50/63], Loss: 0.3286,                   Dice: 87.29, HD: 8.80\n\nEpoch: [37/100], Avg Loss: 0.324,               Train Dice: 86.56, Train HD: 8.96, Time : 12 sec\nAdjusting learning rate of group 0 to 6.9857e-04.\n\n\nEpoch: [38/100], Batch: [25/63], Loss: 0.4105,                   Dice: 84.64, HD: 8.85\nEpoch: [38/100], Batch: [50/63], Loss: 0.2263,                   Dice: 86.11, HD: 9.19\n\nEpoch: [38/100], Avg Loss: 0.328,               Train Dice: 85.16, Train HD: 9.38, Time : 12 sec\nAdjusting learning rate of group 0 to 6.8406e-04.\n\n\nEpoch: [39/100], Batch: [25/63], Loss: 0.3936,                   Dice: 82.50, HD: 9.93\nEpoch: [39/100], Batch: [50/63], Loss: 0.4220,                   Dice: 83.71, HD: 10.27\n\nEpoch: [39/100], Avg Loss: 0.318,               Train Dice: 84.50, Train HD: 9.90, Time : 12 sec\nAdjusting learning rate of group 0 to 6.6937e-04.\n\n\nEpoch: [40/100], Batch: [25/63], Loss: 0.4125,                   Dice: 86.54, HD: 7.98\nEpoch: [40/100], Batch: [50/63], Loss: 0.3036,                   Dice: 85.91, HD: 8.59\n\nEpoch: [40/100], Avg Loss: 0.317,               Train Dice: 85.77, Train HD: 8.66, Time : 12 sec\nAdjusting learning rate of group 0 to 6.5451e-04.\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : PROMISE12, Test Avg Dice : 68.31, Test Avg HD : 24.86, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : ISBI, Test Avg Dice : 78.68, Test Avg HD : 15.61, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [40/100], Dataset : DECATHLON, Test Avg Dice : 83.94, Test Avg HD : 10.95, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [41/100], Batch: [25/63], Loss: 0.2906,                   Dice: 87.76, HD: 7.39\nEpoch: [41/100], Batch: [50/63], Loss: 0.3249,                   Dice: 86.19, HD: 9.06\n\nEpoch: [41/100], Avg Loss: 0.324,               Train Dice: 85.85, Train HD: 10.19, Time : 11 sec\nAdjusting learning rate of group 0 to 6.3950e-04.\n\n\nEpoch: [42/100], Batch: [25/63], Loss: 0.4010,                   Dice: 81.90, HD: 12.33\nEpoch: [42/100], Batch: [50/63], Loss: 0.4207,                   Dice: 83.63, HD: 11.36\n\nEpoch: [42/100], Avg Loss: 0.342,               Train Dice: 83.08, Train HD: 11.04, Time : 12 sec\nAdjusting learning rate of group 0 to 6.2434e-04.\n\n\nEpoch: [43/100], Batch: [25/63], Loss: 0.3759,                   Dice: 89.73, HD: 8.02\nEpoch: [43/100], Batch: [50/63], Loss: 0.5025,                   Dice: 86.93, HD: 8.74\n\nEpoch: [43/100], Avg Loss: 0.320,               Train Dice: 86.46, Train HD: 8.80, Time : 11 sec\nAdjusting learning rate of group 0 to 6.0907e-04.\n\n\nEpoch: [44/100], Batch: [25/63], Loss: 0.1777,                   Dice: 86.32, HD: 8.64\nEpoch: [44/100], Batch: [50/63], Loss: 0.4293,                   Dice: 85.91, HD: 9.38\n\nEpoch: [44/100], Avg Loss: 0.320,               Train Dice: 86.60, Train HD: 9.33, Time : 11 sec\nAdjusting learning rate of group 0 to 5.9369e-04.\n\n\nEpoch: [45/100], Batch: [25/63], Loss: 0.4881,                   Dice: 84.37, HD: 10.93\nEpoch: [45/100], Batch: [50/63], Loss: 0.3653,                   Dice: 85.85, HD: 9.42\n\nEpoch: [45/100], Avg Loss: 0.328,               Train Dice: 84.90, Train HD: 10.23, Time : 12 sec\nAdjusting learning rate of group 0 to 5.7822e-04.\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : PROMISE12, Test Avg Dice : 49.42, Test Avg HD : 44.45, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : ISBI, Test Avg Dice : 69.21, Test Avg HD : 30.51, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [45/100], Dataset : DECATHLON, Test Avg Dice : 77.71, Test Avg HD : 18.11, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [46/100], Batch: [25/63], Loss: 0.3433,                   Dice: 84.63, HD: 9.70\nEpoch: [46/100], Batch: [50/63], Loss: 0.3766,                   Dice: 85.51, HD: 9.16\n\nEpoch: [46/100], Avg Loss: 0.321,               Train Dice: 86.07, Train HD: 9.16, Time : 12 sec\nAdjusting learning rate of group 0 to 5.6267e-04.\n\n\nEpoch: [47/100], Batch: [25/63], Loss: 0.2607,                   Dice: 88.85, HD: 7.83\nEpoch: [47/100], Batch: [50/63], Loss: 0.2677,                   Dice: 85.76, HD: 8.74\n\nEpoch: [47/100], Avg Loss: 0.320,               Train Dice: 85.82, Train HD: 8.89, Time : 11 sec\nAdjusting learning rate of group 0 to 5.4705e-04.\n\n\nEpoch: [48/100], Batch: [25/63], Loss: 0.1905,                   Dice: 87.90, HD: 6.81\nEpoch: [48/100], Batch: [50/63], Loss: 0.3900,                   Dice: 86.82, HD: 8.71\n\nEpoch: [48/100], Avg Loss: 0.322,               Train Dice: 86.97, Train HD: 8.92, Time : 12 sec\nAdjusting learning rate of group 0 to 5.3140e-04.\n\n\nEpoch: [49/100], Batch: [25/63], Loss: 0.2948,                   Dice: 86.76, HD: 9.73\nEpoch: [49/100], Batch: [50/63], Loss: 0.4081,                   Dice: 86.20, HD: 10.20\n\nEpoch: [49/100], Avg Loss: 0.316,               Train Dice: 86.55, Train HD: 9.78, Time : 11 sec\nAdjusting learning rate of group 0 to 5.1571e-04.\n\n\nEpoch: [50/100], Batch: [25/63], Loss: 0.3788,                   Dice: 86.16, HD: 9.50\nEpoch: [50/100], Batch: [50/63], Loss: 0.1239,                   Dice: 85.21, HD: 8.50\n\nEpoch: [50/100], Avg Loss: 0.315,               Train Dice: 86.73, Train HD: 8.00, Time : 11 sec\nAdjusting learning rate of group 0 to 5.0000e-04.\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : PROMISE12, Test Avg Dice : 60.53, Test Avg HD : 25.89, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : ISBI, Test Avg Dice : 74.13, Test Avg HD : 20.76, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [50/100], Dataset : DECATHLON, Test Avg Dice : 80.56, Test Avg HD : 13.27, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [51/100], Batch: [25/63], Loss: 0.1934,                   Dice: 87.27, HD: 10.07\nEpoch: [51/100], Batch: [50/63], Loss: 0.4042,                   Dice: 87.01, HD: 9.62\n\nEpoch: [51/100], Avg Loss: 0.321,               Train Dice: 86.30, Train HD: 8.84, Time : 11 sec\nAdjusting learning rate of group 0 to 4.8429e-04.\n\n\nEpoch: [52/100], Batch: [25/63], Loss: 0.3471,                   Dice: 86.08, HD: 9.29\nEpoch: [52/100], Batch: [50/63], Loss: 0.3663,                   Dice: 87.18, HD: 8.06\n\nEpoch: [52/100], Avg Loss: 0.313,               Train Dice: 86.86, Train HD: 8.40, Time : 12 sec\nAdjusting learning rate of group 0 to 4.6860e-04.\n\n\nEpoch: [53/100], Batch: [25/63], Loss: 0.3555,                   Dice: 87.03, HD: 8.03\nEpoch: [53/100], Batch: [50/63], Loss: 0.1359,                   Dice: 86.21, HD: 8.77\n\nEpoch: [53/100], Avg Loss: 0.313,               Train Dice: 87.36, Train HD: 8.35, Time : 11 sec\nAdjusting learning rate of group 0 to 4.5295e-04.\n\n\nEpoch: [54/100], Batch: [25/63], Loss: 0.4050,                   Dice: 86.44, HD: 8.49\nEpoch: [54/100], Batch: [50/63], Loss: 0.3479,                   Dice: 87.16, HD: 7.95\n\nEpoch: [54/100], Avg Loss: 0.310,               Train Dice: 87.53, Train HD: 8.03, Time : 12 sec\nAdjusting learning rate of group 0 to 4.3733e-04.\n\n\nEpoch: [55/100], Batch: [25/63], Loss: 0.3905,                   Dice: 88.78, HD: 7.93\nEpoch: [55/100], Batch: [50/63], Loss: 0.5223,                   Dice: 87.12, HD: 8.68\n\nEpoch: [55/100], Avg Loss: 0.311,               Train Dice: 86.74, Train HD: 8.36, Time : 11 sec\nAdjusting learning rate of group 0 to 4.2178e-04.\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : PROMISE12, Test Avg Dice : 65.98, Test Avg HD : 25.95, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : ISBI, Test Avg Dice : 77.06, Test Avg HD : 16.86, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [55/100], Dataset : DECATHLON, Test Avg Dice : 84.24, Test Avg HD : 10.95, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [56/100], Batch: [25/63], Loss: 0.3780,                   Dice: 89.14, HD: 10.53\nEpoch: [56/100], Batch: [50/63], Loss: 0.3205,                   Dice: 88.20, HD: 9.24\n\nEpoch: [56/100], Avg Loss: 0.308,               Train Dice: 87.83, Train HD: 9.03, Time : 12 sec\nAdjusting learning rate of group 0 to 4.0631e-04.\n\n\nEpoch: [57/100], Batch: [25/63], Loss: 0.2931,                   Dice: 82.94, HD: 9.06\nEpoch: [57/100], Batch: [50/63], Loss: 0.3553,                   Dice: 85.54, HD: 8.17\n\nEpoch: [57/100], Avg Loss: 0.326,               Train Dice: 85.56, Train HD: 8.01, Time : 12 sec\nAdjusting learning rate of group 0 to 3.9093e-04.\n\n\nEpoch: [58/100], Batch: [25/63], Loss: 0.3883,                   Dice: 86.38, HD: 8.55\nEpoch: [58/100], Batch: [50/63], Loss: 0.4068,                   Dice: 87.93, HD: 8.16\n\nEpoch: [58/100], Avg Loss: 0.317,               Train Dice: 87.71, Train HD: 8.30, Time : 11 sec\nAdjusting learning rate of group 0 to 3.7566e-04.\n\n\nEpoch: [59/100], Batch: [25/63], Loss: 0.3310,                   Dice: 88.64, HD: 7.44\nEpoch: [59/100], Batch: [50/63], Loss: 0.3760,                   Dice: 88.36, HD: 8.37\n\nEpoch: [59/100], Avg Loss: 0.310,               Train Dice: 88.54, Train HD: 8.10, Time : 11 sec\nAdjusting learning rate of group 0 to 3.6050e-04.\n\n\nEpoch: [60/100], Batch: [25/63], Loss: 0.3885,                   Dice: 87.11, HD: 7.53\nEpoch: [60/100], Batch: [50/63], Loss: 0.1457,                   Dice: 87.01, HD: 8.51\n\nEpoch: [60/100], Avg Loss: 0.309,               Train Dice: 86.59, Train HD: 8.55, Time : 12 sec\nAdjusting learning rate of group 0 to 3.4549e-04.\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : PROMISE12, Test Avg Dice : 66.09, Test Avg HD : 26.29, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : ISBI, Test Avg Dice : 77.88, Test Avg HD : 17.13, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [60/100], Dataset : DECATHLON, Test Avg Dice : 84.90, Test Avg HD : 9.54, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [61/100], Batch: [25/63], Loss: 0.3656,                   Dice: 86.55, HD: 8.16\nEpoch: [61/100], Batch: [50/63], Loss: 0.4197,                   Dice: 86.68, HD: 8.12\n\nEpoch: [61/100], Avg Loss: 0.314,               Train Dice: 87.19, Train HD: 7.87, Time : 12 sec\nAdjusting learning rate of group 0 to 3.3063e-04.\n\n\nEpoch: [62/100], Batch: [25/63], Loss: 0.1678,                   Dice: 88.17, HD: 7.82\nEpoch: [62/100], Batch: [50/63], Loss: 0.1112,                   Dice: 89.83, HD: 7.36\n\nEpoch: [62/100], Avg Loss: 0.299,               Train Dice: 89.10, Train HD: 7.45, Time : 11 sec\nAdjusting learning rate of group 0 to 3.1594e-04.\n\n\nEpoch: [63/100], Batch: [25/63], Loss: 0.3895,                   Dice: 88.79, HD: 8.45\nEpoch: [63/100], Batch: [50/63], Loss: 0.1605,                   Dice: 88.06, HD: 8.93\n\nEpoch: [63/100], Avg Loss: 0.314,               Train Dice: 87.22, Train HD: 8.64, Time : 12 sec\nAdjusting learning rate of group 0 to 3.0143e-04.\n\n\nEpoch: [64/100], Batch: [25/63], Loss: 0.2636,                   Dice: 87.39, HD: 7.91\nEpoch: [64/100], Batch: [50/63], Loss: 0.2362,                   Dice: 87.49, HD: 8.44\n\nEpoch: [64/100], Avg Loss: 0.306,               Train Dice: 87.27, Train HD: 8.01, Time : 12 sec\nAdjusting learning rate of group 0 to 2.8711e-04.\n\n\nEpoch: [65/100], Batch: [25/63], Loss: 0.1512,                   Dice: 83.97, HD: 9.62\nEpoch: [65/100], Batch: [50/63], Loss: 0.2013,                   Dice: 86.35, HD: 9.03\n\nEpoch: [65/100], Avg Loss: 0.309,               Train Dice: 87.37, Train HD: 8.47, Time : 11 sec\nAdjusting learning rate of group 0 to 2.7300e-04.\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : PROMISE12, Test Avg Dice : 58.06, Test Avg HD : 25.85, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : ISBI, Test Avg Dice : 76.43, Test Avg HD : 17.73, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [65/100], Dataset : DECATHLON, Test Avg Dice : 84.40, Test Avg HD : 10.85, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [66/100], Batch: [25/63], Loss: 0.3259,                   Dice: 85.54, HD: 7.98\nEpoch: [66/100], Batch: [50/63], Loss: 0.5049,                   Dice: 86.74, HD: 8.66\n\nEpoch: [66/100], Avg Loss: 0.308,               Train Dice: 87.01, Train HD: 7.95, Time : 12 sec\nAdjusting learning rate of group 0 to 2.5912e-04.\n\n\nEpoch: [67/100], Batch: [25/63], Loss: 0.4006,                   Dice: 81.09, HD: 10.04\nEpoch: [67/100], Batch: [50/63], Loss: 0.2503,                   Dice: 84.51, HD: 8.57\n\nEpoch: [67/100], Avg Loss: 0.316,               Train Dice: 85.53, Train HD: 8.32, Time : 12 sec\nAdjusting learning rate of group 0 to 2.4548e-04.\n\n\nEpoch: [68/100], Batch: [25/63], Loss: 0.3750,                   Dice: 87.93, HD: 7.41\nEpoch: [68/100], Batch: [50/63], Loss: 0.2923,                   Dice: 88.40, HD: 7.23\n\nEpoch: [68/100], Avg Loss: 0.307,               Train Dice: 88.91, Train HD: 7.08, Time : 12 sec\nAdjusting learning rate of group 0 to 2.3209e-04.\n\n\nEpoch: [69/100], Batch: [25/63], Loss: 0.3177,                   Dice: 87.45, HD: 9.05\nEpoch: [69/100], Batch: [50/63], Loss: 0.4005,                   Dice: 87.90, HD: 7.69\n\nEpoch: [69/100], Avg Loss: 0.300,               Train Dice: 88.38, Train HD: 7.70, Time : 12 sec\nAdjusting learning rate of group 0 to 2.1896e-04.\n\n\nEpoch: [70/100], Batch: [25/63], Loss: 0.3786,                   Dice: 87.99, HD: 7.77\nEpoch: [70/100], Batch: [50/63], Loss: 0.2628,                   Dice: 88.67, HD: 7.19\n\nEpoch: [70/100], Avg Loss: 0.302,               Train Dice: 89.25, Train HD: 7.29, Time : 12 sec\nAdjusting learning rate of group 0 to 2.0611e-04.\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : PROMISE12, Test Avg Dice : 54.26, Test Avg HD : 24.67, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : ISBI, Test Avg Dice : 77.36, Test Avg HD : 17.04, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [70/100], Dataset : DECATHLON, Test Avg Dice : 83.18, Test Avg HD : 10.06, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [71/100], Batch: [25/63], Loss: 0.3495,                   Dice: 90.68, HD: 7.17\nEpoch: [71/100], Batch: [50/63], Loss: 0.3485,                   Dice: 89.32, HD: 7.25\n\nEpoch: [71/100], Avg Loss: 0.301,               Train Dice: 88.19, Train HD: 7.75, Time : 11 sec\nAdjusting learning rate of group 0 to 1.9355e-04.\n\n\nEpoch: [72/100], Batch: [25/63], Loss: 0.3075,                   Dice: 88.90, HD: 6.30\nEpoch: [72/100], Batch: [50/63], Loss: 0.2483,                   Dice: 88.42, HD: 7.08\n\nEpoch: [72/100], Avg Loss: 0.306,               Train Dice: 87.74, Train HD: 7.79, Time : 12 sec\nAdjusting learning rate of group 0 to 1.8129e-04.\n\n\nEpoch: [73/100], Batch: [25/63], Loss: 0.3717,                   Dice: 90.02, HD: 6.48\nEpoch: [73/100], Batch: [50/63], Loss: 0.2132,                   Dice: 90.08, HD: 6.73\n\nEpoch: [73/100], Avg Loss: 0.302,               Train Dice: 89.31, Train HD: 7.03, Time : 11 sec\nAdjusting learning rate of group 0 to 1.6934e-04.\n\n\nEpoch: [74/100], Batch: [25/63], Loss: 0.3334,                   Dice: 87.22, HD: 7.90\nEpoch: [74/100], Batch: [50/63], Loss: 0.3085,                   Dice: 89.13, HD: 7.07\n\nEpoch: [74/100], Avg Loss: 0.303,               Train Dice: 88.97, Train HD: 7.13, Time : 11 sec\nAdjusting learning rate of group 0 to 1.5773e-04.\n\n\nEpoch: [75/100], Batch: [25/63], Loss: 0.4040,                   Dice: 86.73, HD: 6.95\nEpoch: [75/100], Batch: [50/63], Loss: 0.2562,                   Dice: 88.73, HD: 7.27\n\nEpoch: [75/100], Avg Loss: 0.301,               Train Dice: 89.05, Train HD: 7.10, Time : 13 sec\nAdjusting learning rate of group 0 to 1.4645e-04.\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : PROMISE12, Test Avg Dice : 48.48, Test Avg HD : 25.88, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : ISBI, Test Avg Dice : 74.95, Test Avg HD : 17.04, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [75/100], Dataset : DECATHLON, Test Avg Dice : 81.30, Test Avg HD : 13.76, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [76/100], Batch: [25/63], Loss: 0.3289,                   Dice: 86.77, HD: 8.72\nEpoch: [76/100], Batch: [50/63], Loss: 0.3034,                   Dice: 87.40, HD: 7.66\n\nEpoch: [76/100], Avg Loss: 0.303,               Train Dice: 88.25, Train HD: 7.57, Time : 12 sec\nAdjusting learning rate of group 0 to 1.3552e-04.\n\n\nEpoch: [77/100], Batch: [25/63], Loss: 0.1878,                   Dice: 88.07, HD: 7.72\nEpoch: [77/100], Batch: [50/63], Loss: 0.1394,                   Dice: 87.80, HD: 7.11\n\nEpoch: [77/100], Avg Loss: 0.302,               Train Dice: 88.93, Train HD: 6.87, Time : 11 sec\nAdjusting learning rate of group 0 to 1.2494e-04.\n\n\nEpoch: [78/100], Batch: [25/63], Loss: 0.1108,                   Dice: 87.24, HD: 7.97\nEpoch: [78/100], Batch: [50/63], Loss: 0.2529,                   Dice: 89.17, HD: 7.39\n\nEpoch: [78/100], Avg Loss: 0.295,               Train Dice: 88.98, Train HD: 7.56, Time : 12 sec\nAdjusting learning rate of group 0 to 1.1474e-04.\n\n\nEpoch: [79/100], Batch: [25/63], Loss: 0.4318,                   Dice: 88.16, HD: 7.53\nEpoch: [79/100], Batch: [50/63], Loss: 0.3353,                   Dice: 89.87, HD: 6.86\n\nEpoch: [79/100], Avg Loss: 0.295,               Train Dice: 89.29, Train HD: 7.51, Time : 12 sec\nAdjusting learning rate of group 0 to 1.0492e-04.\n\n\nEpoch: [80/100], Batch: [25/63], Loss: 0.3690,                   Dice: 89.13, HD: 7.79\nEpoch: [80/100], Batch: [50/63], Loss: 0.3176,                   Dice: 89.65, HD: 7.11\n\nEpoch: [80/100], Avg Loss: 0.294,               Train Dice: 89.82, Train HD: 7.07, Time : 12 sec\nAdjusting learning rate of group 0 to 9.5492e-05.\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : PROMISE12, Test Avg Dice : 41.41, Test Avg HD : 29.75, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : ISBI, Test Avg Dice : 75.21, Test Avg HD : 16.97, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [80/100], Dataset : DECATHLON, Test Avg Dice : 81.36, Test Avg HD : 11.56, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [81/100], Batch: [25/63], Loss: 0.3459,                   Dice: 88.10, HD: 7.54\nEpoch: [81/100], Batch: [50/63], Loss: 0.3720,                   Dice: 88.60, HD: 7.35\n\nEpoch: [81/100], Avg Loss: 0.303,               Train Dice: 89.58, Train HD: 7.09, Time : 12 sec\nAdjusting learning rate of group 0 to 8.6460e-05.\n\n\nEpoch: [82/100], Batch: [25/63], Loss: 0.3083,                   Dice: 87.50, HD: 7.46\nEpoch: [82/100], Batch: [50/63], Loss: 0.3674,                   Dice: 88.88, HD: 6.71\n\nEpoch: [82/100], Avg Loss: 0.296,               Train Dice: 88.52, Train HD: 6.82, Time : 11 sec\nAdjusting learning rate of group 0 to 7.7836e-05.\n\n\nEpoch: [83/100], Batch: [25/63], Loss: 0.2117,                   Dice: 88.21, HD: 7.66\nEpoch: [83/100], Batch: [50/63], Loss: 0.4864,                   Dice: 87.82, HD: 7.39\n\nEpoch: [83/100], Avg Loss: 0.307,               Train Dice: 88.41, Train HD: 7.10, Time : 11 sec\nAdjusting learning rate of group 0 to 6.9629e-05.\n\n\nEpoch: [84/100], Batch: [25/63], Loss: 0.2823,                   Dice: 91.18, HD: 5.81\nEpoch: [84/100], Batch: [50/63], Loss: 0.2117,                   Dice: 88.36, HD: 6.51\n\nEpoch: [84/100], Avg Loss: 0.302,               Train Dice: 88.26, Train HD: 6.92, Time : 12 sec\nAdjusting learning rate of group 0 to 6.1847e-05.\n\n\nEpoch: [85/100], Batch: [25/63], Loss: 0.2358,                   Dice: 88.33, HD: 6.18\nEpoch: [85/100], Batch: [50/63], Loss: 0.1933,                   Dice: 90.11, HD: 6.23\n\nEpoch: [85/100], Avg Loss: 0.309,               Train Dice: 88.76, Train HD: 6.77, Time : 11 sec\nAdjusting learning rate of group 0 to 5.4497e-05.\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : PROMISE12, Test Avg Dice : 53.61, Test Avg HD : 31.69, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : ISBI, Test Avg Dice : 77.34, Test Avg HD : 15.71, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [85/100], Dataset : DECATHLON, Test Avg Dice : 83.60, Test Avg HD : 11.70, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [86/100], Batch: [25/63], Loss: 0.0869,                   Dice: 91.70, HD: 6.44\nEpoch: [86/100], Batch: [50/63], Loss: 0.3761,                   Dice: 91.35, HD: 6.26\n\nEpoch: [86/100], Avg Loss: 0.297,               Train Dice: 89.87, Train HD: 7.15, Time : 11 sec\nAdjusting learning rate of group 0 to 4.7586e-05.\n\n\nEpoch: [87/100], Batch: [25/63], Loss: 0.3282,                   Dice: 87.67, HD: 8.45\nEpoch: [87/100], Batch: [50/63], Loss: 0.1052,                   Dice: 89.93, HD: 7.23\n\nEpoch: [87/100], Avg Loss: 0.298,               Train Dice: 89.72, Train HD: 7.23, Time : 12 sec\nAdjusting learning rate of group 0 to 4.1123e-05.\n\n\nEpoch: [88/100], Batch: [25/63], Loss: 0.5003,                   Dice: 91.92, HD: 6.03\nEpoch: [88/100], Batch: [50/63], Loss: 0.3645,                   Dice: 89.97, HD: 6.04\n\nEpoch: [88/100], Avg Loss: 0.296,               Train Dice: 89.79, Train HD: 6.38, Time : 11 sec\nAdjusting learning rate of group 0 to 3.5112e-05.\n\n\nEpoch: [89/100], Batch: [25/63], Loss: 0.2766,                   Dice: 90.29, HD: 7.03\nEpoch: [89/100], Batch: [50/63], Loss: 0.0784,                   Dice: 90.27, HD: 7.24\n\nEpoch: [89/100], Avg Loss: 0.290,               Train Dice: 90.42, Train HD: 6.80, Time : 11 sec\nAdjusting learning rate of group 0 to 2.9560e-05.\n\n\nEpoch: [90/100], Batch: [25/63], Loss: 0.4083,                   Dice: 89.65, HD: 6.95\nEpoch: [90/100], Batch: [50/63], Loss: 0.1909,                   Dice: 91.03, HD: 6.58\n\nEpoch: [90/100], Avg Loss: 0.300,               Train Dice: 90.81, Train HD: 7.13, Time : 12 sec\nAdjusting learning rate of group 0 to 2.4472e-05.\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : PROMISE12, Test Avg Dice : 51.02, Test Avg HD : 29.32, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : ISBI, Test Avg Dice : 77.17, Test Avg HD : 15.92, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [90/100], Dataset : DECATHLON, Test Avg Dice : 83.01, Test Avg HD : 10.67, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [91/100], Batch: [25/63], Loss: 0.2121,                   Dice: 88.07, HD: 7.93\nEpoch: [91/100], Batch: [50/63], Loss: 0.2490,                   Dice: 88.91, HD: 6.77\n\nEpoch: [91/100], Avg Loss: 0.297,               Train Dice: 89.02, Train HD: 6.61, Time : 12 sec\nAdjusting learning rate of group 0 to 1.9853e-05.\n\n\nEpoch: [92/100], Batch: [25/63], Loss: 0.1486,                   Dice: 90.37, HD: 6.20\nEpoch: [92/100], Batch: [50/63], Loss: 0.3559,                   Dice: 90.06, HD: 6.63\n\nEpoch: [92/100], Avg Loss: 0.301,               Train Dice: 89.23, Train HD: 6.67, Time : 12 sec\nAdjusting learning rate of group 0 to 1.5708e-05.\n\n\nEpoch: [93/100], Batch: [25/63], Loss: 0.4261,                   Dice: 87.68, HD: 8.50\nEpoch: [93/100], Batch: [50/63], Loss: 0.0848,                   Dice: 89.33, HD: 7.17\n\nEpoch: [93/100], Avg Loss: 0.294,               Train Dice: 89.42, Train HD: 6.88, Time : 12 sec\nAdjusting learning rate of group 0 to 1.2042e-05.\n\n\nEpoch: [94/100], Batch: [25/63], Loss: 0.3745,                   Dice: 90.41, HD: 6.96\nEpoch: [94/100], Batch: [50/63], Loss: 0.3025,                   Dice: 88.31, HD: 6.89\n\nEpoch: [94/100], Avg Loss: 0.301,               Train Dice: 88.47, Train HD: 6.88, Time : 12 sec\nAdjusting learning rate of group 0 to 8.8564e-06.\n\n\nEpoch: [95/100], Batch: [25/63], Loss: 0.3389,                   Dice: 89.13, HD: 6.09\nEpoch: [95/100], Batch: [50/63], Loss: 0.4100,                   Dice: 89.72, HD: 6.68\n\nEpoch: [95/100], Avg Loss: 0.303,               Train Dice: 89.84, Train HD: 6.88, Time : 12 sec\nAdjusting learning rate of group 0 to 6.1558e-06.\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : PROMISE12, Test Avg Dice : 50.93, Test Avg HD : 25.89, Time : 6 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : ISBI, Test Avg Dice : 76.79, Test Avg HD : 15.98, Time : 14 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [95/100], Dataset : DECATHLON, Test Avg Dice : 83.05, Test Avg HD : 10.86, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n\n\nEpoch: [96/100], Batch: [25/63], Loss: 0.2471,                   Dice: 90.81, HD: 6.28\nEpoch: [96/100], Batch: [50/63], Loss: 0.5078,                   Dice: 91.01, HD: 7.10\n\nEpoch: [96/100], Avg Loss: 0.300,               Train Dice: 90.72, Train HD: 6.91, Time : 12 sec\nAdjusting learning rate of group 0 to 3.9426e-06.\n\n\nEpoch: [97/100], Batch: [25/63], Loss: 0.1013,                   Dice: 86.83, HD: 7.78\nEpoch: [97/100], Batch: [50/63], Loss: 0.1723,                   Dice: 88.99, HD: 6.86\n\nEpoch: [97/100], Avg Loss: 0.298,               Train Dice: 89.28, Train HD: 6.92, Time : 12 sec\nAdjusting learning rate of group 0 to 2.2190e-06.\n\n\nEpoch: [98/100], Batch: [25/63], Loss: 0.4287,                   Dice: 87.75, HD: 6.27\nEpoch: [98/100], Batch: [50/63], Loss: 0.3631,                   Dice: 88.81, HD: 6.79\n\nEpoch: [98/100], Avg Loss: 0.298,               Train Dice: 89.54, Train HD: 6.84, Time : 12 sec\nAdjusting learning rate of group 0 to 9.8664e-07.\n\n\nEpoch: [99/100], Batch: [25/63], Loss: 0.3352,                   Dice: 90.73, HD: 7.01\nEpoch: [99/100], Batch: [50/63], Loss: 0.2072,                   Dice: 90.17, HD: 7.08\n\nEpoch: [99/100], Avg Loss: 0.306,               Train Dice: 89.58, Train HD: 7.09, Time : 12 sec\nAdjusting learning rate of group 0 to 2.4672e-07.\n\n\nEpoch: [100/100], Batch: [25/63], Loss: 0.2431,                   Dice: 88.83, HD: 5.73\nEpoch: [100/100], Batch: [50/63], Loss: 0.4109,                   Dice: 89.66, HD: 6.42\n\nEpoch: [100/100], Avg Loss: 0.304,               Train Dice: 89.86, Train HD: 6.25, Time : 11 sec\nAdjusting learning rate of group 0 to 0.0000e+00.\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : PROMISE12, Test Avg Dice : 50.17, Test Avg HD : 26.50, Time : 5 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : ISBI, Test Avg Dice : 76.57, Test Avg HD : 16.12, Time : 15 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n---------------------------------------------------------------------------\nEpoch : [100/100], Dataset : DECATHLON, Test Avg Dice : 82.96, Test Avg HD : 11.04, Time : 3 sec\n---------------------------------------------------------------------------\nLogged data to wandb\n","output_type":"stream"}]},{"cell_type":"code","source":"replay_percentage = 0.1\ntrain_samples_count = len(dataset_map[dataset_name]['train']['images'])\nreplay_count = int(train_samples_count * replay_percentage)\nprint(f\"Storing {replay_count} Decathlon Samples to replay buffer\")\nidxs = idxs = list(map(int, np.linspace(0, train_samples_count-1, num=replay_count).tolist()))\nreplay_buffer['train']['images'] +=  [dataset_map[dataset_name]['train']['images'][idx] for idx in idxs]\nreplay_buffer['train']['labels'] +=  [dataset_map[dataset_name]['train']['labels'][idx] for idx in idxs]\nprint(f\"Current replay buffer size : {len(replay_buffer['train']['labels'])}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-10T10:05:14.281130Z","iopub.execute_input":"2022-09-10T10:05:14.281450Z","iopub.status.idle":"2022-09-10T10:05:14.293244Z","shell.execute_reply.started":"2022-09-10T10:05:14.281420Z","shell.execute_reply":"2022-09-10T10:05:14.291627Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Storing 6 Decathlon Samples to replay buffer\nCurrent replay buffer size : 16\n","output_type":"stream"}]}]}