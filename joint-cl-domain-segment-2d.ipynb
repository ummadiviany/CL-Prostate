{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Continual Learning Pre - Flight Test Methods : Joint Learning, Sequential Learning","metadata":{}},{"cell_type":"markdown","source":"## Necessary Installs","metadata":{}},{"cell_type":"code","source":"!pip install -q monai einops","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:04.060691Z","iopub.execute_input":"2022-08-20T19:21:04.061124Z","iopub.status.idle":"2022-08-20T19:21:13.855842Z","shell.execute_reply.started":"2022-08-20T19:21:04.061039Z","shell.execute_reply":"2022-08-20T19:21:13.854638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Necessary Imports","metadata":{}},{"cell_type":"code","source":"# imports and installs\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport nibabel as nib\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\nfrom torch.optim import SGD, Adam, ASGD\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport monai\nfrom monai.transforms import (ScaleIntensityRange, Compose, AddChannel, RandSpatialCrop, ToTensor, \n                            RandAxisFlip, Activations, AsDiscrete, Resize, RandRotate, RandFlip, EnsureType,\n                             KeepLargestConnectedComponent)\nfrom monai.metrics import DiceMetric, HausdorffDistanceMetric\nfrom monai.inferers import sliding_window_inference\nfrom monai.losses import DiceLoss, FocalLoss, GeneralizedDiceLoss, DiceCELoss, DiceFocalLoss\nfrom monai.networks.nets import UNet, VNet, UNETR, SwinUNETR, AttentionUnet\nfrom monai.data import decollate_batch, ImageDataset\nfrom monai.utils import set_determinism\nimport os\nimport wandb\nfrom time import time\nfrom einops import rearrange\nfrom einops.layers.torch import Rearrange\nfrom torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingLR\nfrom random import sample\n\ntorch.manual_seed(2000)\nset_determinism(seed=2000)\n\nwandb_log = True","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:13.858781Z","iopub.execute_input":"2022-08-20T19:21:13.859181Z","iopub.status.idle":"2022-08-20T19:21:16.299167Z","shell.execute_reply.started":"2022-08-20T19:21:13.859139Z","shell.execute_reply":"2022-08-20T19:21:16.298045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Data Loader ","metadata":{}},{"cell_type":"code","source":"class DecathlonCorrectImage(monai.transforms.Transform):\n    def __call__(self, x : torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        This function is used to preprocess image input data.\n        \n        1. Keep the original intensity values from 0 to 99.9 %\n        2. Scales the intensity range of the image to [0, 1].\n        \"\"\"\n        # x shape is (channel, height, width, depth)\n\n        a_max = np.percentile(x, 99.9)\n        SIR = ScaleIntensityRange(a_min = 0, a_max = a_max, b_min = 0, b_max = 1, clip = True)\n        x = SIR(x)\n        return x\n\nclass DecathlonCorrectLabel(monai.transforms.Transform):\n    def __call__(self, x : torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        This function is used to preprocess image input data.\n        \n        1. Multi class segmentation to binary segmentation(Labels > 0  will be set to 1.).\n        \"\"\"\n        # x shape is (channel, height, width, depth)\n        x[x > 0] = 1\n        return x\n\n\nclass DecathlonProstaeJustMRI(monai.transforms.Transform):\n    def __call__(self, x : torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        This function is used to preprocess image input data.\n        1. For now we only use the first channel(MRI) of the input image and ignoring the \n        ADC map in the second channel.\n        \"\"\"\n        # x shape is (channel, height, width, depth, maps)\n        x = rearrange(x, 'h w d c -> c h w d')\n        return x[0]\n\nclass DecathlonCorrectImage(monai.transforms.Transform):\n    def __call__(self, x : torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        This function is used to preprocess image input data.\n        1. Rotates the image by 270 degrees in the x-y plane.\n        2. Keep the original intensity values from 0 to 99.9 %\n        3. Scales the intensity range of the image to [0, 1].\n        \"\"\"\n        # x shape is (channel, height, width, depth)\n\n        x = np.flip(np.rot90(x, k=3, axes = (1,2)), axis = 2)\n        a_max = np.percentile(x, 99.9)\n        SIR = ScaleIntensityRange(a_min = 0, a_max = a_max, b_min = 0, b_max = 1, clip = True)\n        x = SIR(x)\n        return x\n\nclass DecathlonCorrectLabel(monai.transforms.Transform):\n    def __call__(self, x : torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        This function is used to preprocess image input data.\n        1. Rotates the image by 270 degrees in the x-y plane.\n        2. Multi class segmentation to binary segmentation(Labels > 0  will be set to 1.).\n        \"\"\"\n        # x shape is (channel, height, width, depth)\n        x = np.flip(np.rot90(x, k=3, axes = (1,2)), axis = 2)\n        x[x > 0] = 1\n        return x\n\ndef get_img_label_folds(img_paths, label_paths):\n    \n    fold = list(range(0,len(img_paths)))\n    fold = sample(fold, k=len(fold))\n    fold_imgs = [img_paths[i] for i in fold]\n    fold_labels = [label_paths[i] for i in fold]\n    return fold_imgs, fold_labels\n\n\ndef get_dataloaders(\n    dataset : str ,\n    batch_size : int ,\n    test_size : float ,\n    roi_size : int ,\n    test_shuffle : bool ,\n):\n    \"\"\"_summary_\n\n    Args:\n        dataset (str): dataset name\n        batch_size (int): batch size\n        test_size (float): test size ratio\n    \"\"\"\n\n    dataset_map = {\n        \"promise12\" : {\n            \"data_dir\" : \"../input/promise12-rot-intensity-scale-3d/\",\n#             \"data_dir\" : \"../../MIS/datasets/promise12/rot_scale/\",\n            \"train_img_transform\" : [\n                AddChannel(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                ToTensor()\n                ],\n            \"train_label_transform\" : [\n                AddChannel(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                AsDiscrete(threshold=0.5),\n                ToTensor()\n                ],\n            \"test_img_transform\" : [\n                AddChannel(),\n                ToTensor()\n                ],\n            \"test_label_transfrom\" : [\n                AddChannel(),\n                ToTensor()\n                ],\n            },\n        # Issue in reading the original pixdim for decathlon prostate dataset.\n        # Fix the pixdim by manually setting it to 1.\n        \"decathlon\" : {\n            \"data_dir\" : \"../input/decathlonprostate/Task05_Prostate/\",\n#             \"data_dir\" : \"../../MIS/datasets/Task05_Prostate/\",\n            \"train_img_transform\" : [\n                DecathlonProstaeJustMRI(),\n                AddChannel(),\n                DecathlonCorrectImage(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                ToTensor()\n                ],\n            \"train_label_transform\" : [\n                AddChannel(),\n                DecathlonCorrectLabel(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                AsDiscrete(threshold=0.5),\n                ToTensor()\n                ],\n            \"test_img_transform\" : [\n                DecathlonProstaeJustMRI(),\n                AddChannel(),\n                DecathlonCorrectImage(),\n                ToTensor()\n                ],\n            \"test_label_transfrom\" : [\n                AddChannel(),\n                DecathlonCorrectLabel(),\n                AsDiscrete(threshold=0.5),\n                ToTensor()\n                ],\n            },\n        \"isbi\" : {\n            \"data_dir\" : \"../input/isbiv2-merged/ISBI_V2/\",\n#             \"data_dir\" : \"../../MIS/datasets/ISBI_V2/\",\n            \"remove_indexes\" : [47],\n            \"train_img_transform\" : [\n                AddChannel(),\n                DecathlonCorrectImage(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                ToTensor()\n                ],\n            \"train_label_transform\" : [\n                AddChannel(),\n                DecathlonCorrectLabel(),\n                RandSpatialCrop(roi_size= roi_size, random_center = True, random_size=False),\n                AsDiscrete(threshold=0.5),\n                ToTensor()\n                ],\n            \"test_img_transform\" : [\n                AddChannel(),\n                DecathlonCorrectImage(),\n                ToTensor()\n                ],\n            \"test_label_transfrom\" : [\n                AddChannel(),\n                DecathlonCorrectLabel(),\n                ToTensor()\n                ],\n            }\n    }\n    \n    if dataset not in dataset_map:\n        raise ValueError(\"Dataset {} is not supported\".format(dataset))\n    \n    # Get image paths and label paths\n    \n    dataset_dict = dataset_map[dataset]\n    img_paths = glob(dataset_dict[\"data_dir\"] + \"imagesTr/*.nii\")\n    label_paths = glob(dataset_dict[\"data_dir\"] + \"labelsTr/*.nii\")\n    img_paths.sort()\n    label_paths.sort()\n\n\n    # Remove the indexes that create problems during training\n    # if \"remove_indexes\" in dataset_dict:\n    #     remove_indexes = dataset_dict[\"remove_indexes\"]\n    #     img_paths = [img_paths[i] for i in range(len(img_paths)) if i not in remove_indexes]\n    #     label_paths = [label_paths[i] for i in range(len(label_paths)) if i not in remove_indexes]\n\n    # Get folds\n    images_fold, labels_fold  = get_img_label_folds(img_paths, label_paths)\n#     images_fold, labels_fold  = img_paths, label_paths\n    \n    print(\"Number of images: {}\".format(len(images_fold)))\n    print(\"Number of labels: {}\".format(len(labels_fold)))\n\n    # Get train and test sets\n    train_idx = int(len(images_fold) * (1 - test_size))\n        \n    train_set = ImageDataset(images_fold[:train_idx], labels_fold[:train_idx],\n                            transform=Compose(dataset_dict['train_img_transform']), \n                            seg_transform=Compose(dataset_dict['train_label_transform']))\n\n    test_set = ImageDataset(images_fold[train_idx:], labels_fold[train_idx:],\n                        transform=Compose(dataset_dict['test_img_transform']),\n                        seg_transform=Compose(dataset_dict['test_label_transfrom']))\n\n\n    # Get dataloaders for train and test sets\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=test_shuffle)\n    \n    return train_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:16.301228Z","iopub.execute_input":"2022-08-20T19:21:16.302572Z","iopub.status.idle":"2022-08-20T19:21:16.328777Z","shell.execute_reply.started":"2022-08-20T19:21:16.302528Z","shell.execute_reply":"2022-08-20T19:21:16.327843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize dataset","metadata":{}},{"cell_type":"code","source":"# ----------------------------Get dataloaders--------------------------\nroi_single = 160\ntrain_loader, test_loader = get_dataloaders(\n    dataset=\"decathlon\",\n    batch_size=1,\n    test_size=0.2,\n    roi_size=roi_single,\n    test_shuffle=True,\n)\n\n\nprint(f\"\\nTraining samples : {len(train_loader)}\")\nprint(f\"Testing samples : {len(test_loader)}\")\n\n\nimgs,labels = next(iter(train_loader))\nimgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\nlabels = rearrange(labels, 'b c h w d -> (b d) c h w')\nprint(f\"\\nImage shape : {imgs.shape}\")\nprint(f\"Label shape : {labels.shape}\")\n\nimg_no = 8\nplt.figure(figsize=(6*3,6*1))\nplt.subplot(1,3,1)\nplt.imshow(imgs[img_no,0], cmap='gray')\nplt.axis('off')\nplt.title('Image')\nplt.subplot(1,3,2)\nplt.imshow(labels[img_no,0], cmap='gray')\nplt.axis('off')\nplt.title('Label')\nplt.subplot(1,3,3)\nplt.imshow(imgs[img_no,0], cmap='gray')\nplt.imshow(labels[img_no,0], 'copper', alpha=0.2)\nplt.axis('off')\nplt.title('Overlay')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:16.332451Z","iopub.execute_input":"2022-08-20T19:21:16.332896Z","iopub.status.idle":"2022-08-20T19:21:16.836815Z","shell.execute_reply.started":"2022-08-20T19:21:16.332777Z","shell.execute_reply":"2022-08-20T19:21:16.835447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train - Test Statistics","metadata":{}},{"cell_type":"code","source":"print(f\"\\nTraining samples : {len(train_loader)}\")\nprint(f\"Testing samples : {len(test_loader)}\")\n\n# -----------------------Slices-----------------------------\n\nplt.figure(figsize = (2*7, 1*7))\n\nslices = [label.shape[4] for _, label in train_loader]\n\nplt.subplot(1,2,1)\nplt.hist(slices, )\nplt.xlabel('Slices')\nplt.ylabel('Count')\nplt.title('Training Set')\n\nslices = [label.shape[4] for _, label in test_loader]\nplt.subplot(1,2,2)\nplt.hist(slices, )\nplt.xlabel('Slices')\nplt.ylabel('Count')\nplt.title('Testing set')\n\nplt.suptitle('Slices in Training & Testing Sets')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:16.837894Z","iopub.execute_input":"2022-08-20T19:21:16.838565Z","iopub.status.idle":"2022-08-20T19:21:20.296180Z","shell.execute_reply.started":"2022-08-20T19:21:16.838528Z","shell.execute_reply":"2022-08-20T19:21:20.295197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Config, Loss, Metrics","metadata":{}},{"cell_type":"code","source":"# ----------------------------Train Config-----------------------------------------\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\nmodel = UNet(\n        spatial_dims=2,\n        in_channels=1,\n        out_channels=2,\n        channels=(16, 32, 64, 128, 256),\n        strides=(2, 2, 2, 2),\n        num_res_units=2,\n    ).to(device)\n\nepochs = 100\ninitial_lr = 1e-3\noptimizer = Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n# optimizer = ASGD(model.parameters(), lr=initial_lr)\nscheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=True)\n# scheduler = ExponentialLR(optimizer, gamma=0.98)\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\nhd_metric = HausdorffDistanceMetric(include_background=False, percentile = 95.)\n\n\n# post_trans = Compose([ToTensor(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\npost_pred = Compose([\n    EnsureType(), AsDiscrete(argmax=True, to_onehot=2),\n    KeepLargestConnectedComponent(applied_labels=[1], is_onehot=True, connectivity=2)\n])\npost_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\nargmax = AsDiscrete(argmax=True)\n# dice_loss = DiceLoss(to_onehot_y=True, softmax=True)\n# bce_loss = nn.BCEWithLogitsLoss()\n# ce_loss = nn.CrossEntropyLoss(weight = torch.tensor([1., 20.], device = device))\n# focal_loss = FocalLoss(to_onehot_y = True, weight = [.5, 95.])\ndice_ce_loss = DiceCELoss(to_onehot_y=True, softmax=True,)\n# dice_focal_loss = DiceFocalLoss(to_onehot_y=True, softmax=True, focal_weight = torch.tensor([1., 5.], device = device))\n# focal_weight = torch.tensor([1., 20.], device = device)\n# weight = torch.tensor([1., 5.], device = device)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:20.297708Z","iopub.execute_input":"2022-08-20T19:21:20.298064Z","iopub.status.idle":"2022-08-20T19:21:21.932766Z","shell.execute_reply.started":"2022-08-20T19:21:20.298027Z","shell.execute_reply":"2022-08-20T19:21:21.931699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## WANDB Logging","metadata":{}},{"cell_type":"code","source":"# ------------------------------------WANDB Logging-------------------------------------\nconfig = {\n    \"Model\" : \"UNet2D\",\n    \"Train Input ROI size\" : roi_single,\n#     \"Test Input size\" : (1, 320, 320),\n    \"Test mode\" : f\"Sliding window inference roi = {roi_single}\",\n    \"Batch size\" : \"No of slices in original volume\",\n    \"No of volumes per batch\" : 1,\n    \"Epochs\" : epochs,\n    \"Optimizer\" : \"Adam\",\n    \"Scheduler\" : \"CosineAnnealingLR\",\n    \"Initial LR\" : scheduler.get_last_lr()[0],\n    \"Loss\" : \"DiceCELoss\", \n    \"Train Data Augumentations\" : \"RandSpatialCrop\",\n    \"Test Data Preprocess\" : \"None\",\n    \"Train samples\" : len(train_loader),\n    \"Test Samples\" : len(test_loader),\n#     RandFlip, RandRotate90, RandGaussianNoise, RandGaussSmooth, RandBiasField, RandContrast\n    \"Pred Post Processing\" : \"KeepLargestConnectedComponent\"\n}\nif wandb_log:\n    wandb.login()\n    wandb.init(project=\"CL_Joint\", entity=\"vinayu\", config = config)","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:21.934195Z","iopub.execute_input":"2022-08-20T19:21:21.934855Z","iopub.status.idle":"2022-08-20T19:21:38.795043Z","shell.execute_reply.started":"2022-08-20T19:21:21.934816Z","shell.execute_reply":"2022-08-20T19:21:38.794072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Joint Traning","metadata":{}},{"cell_type":"code","source":"batch_size = 1\ntest_shuffle = True\n\ndatasets = {'promise12' : {\n    'test_size' : 0.1,\n    'roi_size' : 160,\n        },\n            'isbi' : {\n    'test_size' : 0.2,\n    'roi_size' : 192,\n        },\n            'decathlon' : {\n    'test_size' : 0.2,\n    'roi_size' : 160,\n        }\n           }\n\n\ndataloaders_map = {\n    'promise12' : get_dataloaders(\n        dataset = 'promise12',\n        batch_size = batch_size,\n        test_size = datasets['promise12']['test_size'],\n        roi_size = datasets['promise12']['roi_size'],\n        test_shuffle = test_shuffle\n    ),\n    'isbi' : get_dataloaders(\n        dataset = 'isbi',\n        batch_size = batch_size,\n        test_size = datasets['isbi']['test_size'],\n        roi_size = datasets['isbi']['roi_size'],\n        test_shuffle = test_shuffle\n    ),\n    'decathlon' : get_dataloaders(\n        dataset = 'decathlon',\n        batch_size = batch_size,\n        test_size = datasets['decathlon']['test_size'],\n        roi_size = datasets['decathlon']['roi_size'],\n        test_shuffle = test_shuffle\n    )\n}\n\nmetrics_map = {\n    'promise12' : {\n        'promise12_curr_dice' : 0,\n        'promise12_best_dice' : 0,\n        'promise12_curr_hd' : 1e10,\n        'promise12_best_hd' : 1e10,\n        'Epoch' : 0\n    },\n    'isbi' : {\n        'isbi_curr_dice' : 0,\n        'isbi_best_dice' : 0,\n        'isbi_curr_hd' : 1e10,\n        'isbi_best_hd' : 1e10,\n        'Epoch' : 0\n    },\n    'decathlon' : {\n        'decathlon_curr_dice' : 0,\n        'decathlon_best_dice' : 0,\n        'decathlon_curr_hd' : 1e10,\n        'decathlon_best_hd' : 1e10,\n        'Epoch' : 0\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:38.798207Z","iopub.execute_input":"2022-08-20T19:21:38.798528Z","iopub.status.idle":"2022-08-20T19:21:38.823060Z","shell.execute_reply.started":"2022-08-20T19:21:38.798501Z","shell.execute_reply":"2022-08-20T19:21:38.822075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training & Validation ","metadata":{}},{"cell_type":"code","source":"def train():\n    \"\"\"\n    Inputs : No Inputs\n    Outputs : No Outputs\n    Function : Trains all datasets and logs metrics to WANDB\n    \"\"\"\n    \n    train_start = time()\n    epoch_loss = 0\n    model.train()\n    print('\\n')\n    \n    for dataset_name in dataloaders_map:\n        train_loader, test_loader = dataloaders_map[dataset_name]\n        print(f'\\n----------------{dataset_name}----------------')\n        print(f'Training samples : {len(train_loader)}')\n        # Iterating over the dataset\n        for i, (imgs, labels) in enumerate(train_loader, 1):\n\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n            imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n            labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n            optimizer.zero_grad()\n            preds = model(imgs)\n\n            loss = dice_ce_loss(preds, labels)\n\n            preds = [post_pred(i) for i in decollate_batch(preds)]\n            preds = torch.stack(preds)\n            labels = [post_label(i) for i in decollate_batch(labels)]\n            labels = torch.stack(labels)\n        #         Metric scores\n            dice_metric(preds, labels)\n            hd_metric(preds, labels)\n\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n\n            if i % batch_interval == 0:\n                print(f\"Epoch: [{epoch}/{epochs}], Batch: [{i}/{len(train_loader)}], Loss: {loss.item() :.4f}, \\\n                      Dice: {dice_metric.aggregate().item() * 100 :.2f}, HD: {hd_metric.aggregate().item() :.2f}\")\n    \n    # Print metrics, log data, reset metrics\n    \n    print(f\"\\nEpoch: [{epoch}/{epochs}], Avg Loss: {epoch_loss / len(train_loader) :.3f}, \\\n              Train Dice: {dice_metric.aggregate().item() * 100 :.2f}, Train HD: {hd_metric.aggregate().item() :.2f}, Time : {int(time() - train_start)} sec\")\n\n    if wandb_log:\n        wandb.log({\"Train Dice\" : dice_metric.aggregate().item() * 100,\n                   \"Train Hausdorff Distance\" : hd_metric.aggregate().item(),\n                   \"Train Loss\" : epoch_loss / len(train_loader),\n                   \"Learning Rate\" : scheduler.get_last_lr()[0],\n                   \"Epoch\" : epoch })\n\n    dice_metric.reset()\n    hd_metric.reset()\n    scheduler.step()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(test_loader : DataLoader, dataset_name : str):\n    \"\"\"\n    Inputs : Testing dataloader\n    Outputs : Returns Dice, HD\n    Function : Validate on the given dataloader and return the mertics \n    \"\"\"\n    train_start = time()\n    model.eval()\n    with torch.no_grad():\n        # Iterate over all samples in the dataset\n        for i, (imgs, labels) in enumerate(test_loader, 1):\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n            imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n            labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n            roi_size = (datasets[dataset_name]['roi_size'], datasets[dataset_name]['roi_size'])\n            preds = sliding_window_inference(inputs=imgs, roi_size=roi_size, sw_batch_size=4,\n                                            predictor=model, overlap = 0.5, mode = 'gaussian', device=device)\n#                 preds = model(imgs)\n            preds = [post_pred(i) for i in decollate_batch(preds)]\n            preds = torch.stack(preds)\n            labels = [post_label(i) for i in decollate_batch(labels)]\n            labels = torch.stack(labels)\n\n            dice_metric(preds, labels)\n            hd_metric(preds, labels)\n\n        val_dice = dice_metric.aggregate().item()\n        val_hd = hd_metric.aggregate().item()\n        \n        dice_metric.reset()\n        hd_metric.reset()\n        \n        print(\"-\"*75)\n        print(f\"Epoch : [{epoch}/{epochs}], Dataset : {dataset_name.upper()}, Test Avg Dice : {val_dice*100 :.2f}, Test Avg HD : {val_hd :.2f}, Time : {int(time() - train_start)} sec\")\n        print(\"-\"*75)\n        \n        return val_dice, val_hd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The main training & validation loop\n\nprint(\"Training started ... \\n\")\n\nval_interval = 1\nbatch_interval = 20\nbest_dice = -1\n# best_dice_epoch = 0\nbest_hd = 1e10\n# best_hd_epoch = 0\n\n\nfor epoch in range(1, epochs+1):\n    # Trains on all datasets\n    train()\n    \n    # Validation on each dataset individually and log metrics\n    for dataset_name in dataloaders_map:\n        _, test_loader = dataloaders_map[dataset_name]\n        val_dice, val_hd = validate(test_loader, dataset_name)\n        \n        metrics = metrics_map['dataset_name']\n        \n        metrics[f'Epoch'] = epoch\n        metrics[f'{dataset_name}_curr_dice'] = val_dice * 100\n        metrics[f'{dataset_name}_curr_hd'] = val_hd\n        \n        \n        \n        if val_dice > metrics[f'{dataset_name}_best_dice']:\n\n            metrics[f'{dataset_name}_best_dice'] = val_dice * 100\n#             best_dice_epoch = epoch\n#             torch.save(model.state_dict(), \"best_model.pt\")\n#             print(f\"Best model saved at epoch {best_metric_epoch} with Dice {best_metric*100:.2f}\")\n\n\n        if val_hd < metrics[f'{dataset_name}_best_hd'] and val_hd > 0:\n\n            metrics[f'{dataset_name}_best_hd'] = val_hd\n#             best_hd_epoch = epoch\n\n        if wandb_log:\n            # Quantiative metrics\n            wandb.log(metrics)\n\n            # Qualitative resulsts\n            \n#             preds = torch.stack([argmax(c) for c in preds])\n#             labels = torch.stack([argmax(c) for c in labels])\n\n#             f = make_grid(torch.cat([imgs,labels,preds],dim=3), nrow =2, padding = 20, pad_value = 1)\n#             images = wandb.Image(rearrange(f.cpu(), 'c h w -> h w c'), caption=\"Left: Input, Middle : Ground Truth, Right: Prediction\")\n#             wandb.log({\"Predictions\": images, \"Epoch\" : epoch})\n            \n            print('Logged data to wandb')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Training started ... \\n\")\n\n# val_interval = 1\n# batch_interval = 20\n# best_dice = -1\n# best_dice_epoch = 0\n# best_hd = 1e10\n# best_hd_epoch = 0\n\n# # For in epochs\n# for epoch in range(1, epochs+1):\n\n#     # Training\n#     train_start = time()\n#     model.train()\n#     epoch_loss = 0\n#     print('\\n')\n    \n#     # Iterate over datasets\n    \n#     for dataset_name in dataloaders_map:\n#         train_loader, test_loader = dataloaders_map[dataset_name]\n#         print(f'\\n----------------{dataset_name}----------------')\n#         print(f'Training samples : {len(train_loader)}')\n# #         print(f'Testing samples : {len(test_loader)}\\n')\n        \n#         # Iterate over all samples in the dataset\n        \n#         for i, (imgs, labels) in enumerate(train_loader, 1):\n\n#             imgs = imgs.to(device)\n#             labels = labels.to(device)\n#             imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n#             labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n#             optimizer.zero_grad()\n#             preds = model(imgs)\n\n#     #         loss = dice_loss(preds, labels)\n#     #         labels_temp = rearrange(labels, 'b c h w -> (b c) h w')\n#     #         loss = ce_loss(preds, labels_temp.long().to(device))\n#     #         loss = focal_loss(preds, labels)\n#             loss = dice_ce_loss(preds, labels)\n\n#             preds = [post_pred(i) for i in decollate_batch(preds)]\n#             preds = torch.stack(preds)\n#             labels = [post_label(i) for i in decollate_batch(labels)]\n#             labels = torch.stack(labels)\n#     #         Metric scores\n#             dice_metric(preds, labels)\n#             hd_metric(preds, labels)\n\n#             loss.backward()\n#             optimizer.step()\n\n#             epoch_loss += loss.item()\n\n#             if i % batch_interval == 0:\n#                 print(f\"Epoch: [{epoch}/{epochs}], Batch: [{i}/{len(train_loader)}], Loss: {loss.item() :.4f}, \\\n#                       Dice: {dice_metric.aggregate().item() * 100 :.2f}, HD: {hd_metric.aggregate().item() :.2f}\")\n    \n#     # Print metrics, log data, reset metrics\n    \n#     print(f\"\\nEpoch: [{epoch}/{epochs}], Avg Loss: {epoch_loss / len(train_loader) :.3f}, \\\n#               Train Dice: {dice_metric.aggregate().item() * 100 :.2f}, Train HD: {hd_metric.aggregate().item() :.2f}, Time : {int(time() - train_start)} sec\")\n\n#     if wandb_log:\n#         wandb.log({\"Train Dice\" : dice_metric.aggregate().item() * 100,\n#                    \"Train Hausdorff Distance\" : hd_metric.aggregate().item(),\n#                    \"Train Loss\" : epoch_loss / len(train_loader),\n#                    \"Learning Rate\" : scheduler.get_last_lr()[0],\n#                    \"Epoch\" : epoch })\n\n#     dice_metric.reset()\n#     hd_metric.reset()\n#     scheduler.step()\n        \n    \n\n#     # Validation\n#     if epoch % val_interval == 0:\n#         train_start = time()\n#         model.eval()\n#         with torch.no_grad():\n#             for dataset_name in dataloaders_map:\n#                 train_loader, test_loader = dataloaders_map[dataset_name]\n#                 print(f'\\n---------Validating on {dataset_name} - {len(test_loader)} samples---------')\n# #                 print(f'Training samples : {len(train_loader)}')\n\n#                 # Iterate over all samples in the dataset\n#                 for i, (imgs, labels) in enumerate(test_loader, 1):\n#                     imgs = imgs.to(device)\n#                     labels = labels.to(device)\n#                     imgs = rearrange(imgs, 'b c h w d -> (b d) c h w')\n#                     labels = rearrange(labels, 'b c h w d -> (b d) c h w')\n\n#                     roi_size = (datasets[dataset_name]['roi_size'], datasets[dataset_name]['roi_size'])\n#                     preds = sliding_window_inference(inputs=imgs, roi_size=roi_size, sw_batch_size=4,\n#                                                     predictor=model, overlap = 0.5, mode = 'gaussian', device=device)\n#     #                 preds = model(imgs)\n#                     preds = [post_pred(i) for i in decollate_batch(preds)]\n#                     preds = torch.stack(preds)\n#                     labels = [post_label(i) for i in decollate_batch(labels)]\n#                     labels = torch.stack(labels)\n\n#                     dice_metric(preds, labels)\n#                     hd_metric(preds, labels)\n\n#                 val_dice = dice_metric.aggregate().item()\n#                 val_hd = hd_metric.aggregate().item()\n\n#                 print(\"-\"*75)\n#                 print(f\"Epoch : [{epoch}/{epochs}], Test Avg Dice : {val_dice*100 :.2f}, Test Avg HD : {val_hd :.2f}, Time : {int(time() - train_start)} sec\")\n#                 print(\"-\"*75)\n\n\n\n#     if val_dice > best_dice:\n\n#         best_dice = val_dice\n#         best_dice_epoch = epoch\n# #                 torch.save(model.state_dict(), \"best_model.pt\")\n# #                 print(f\"Best model saved at epoch {best_metric_epoch} with Dice {best_metric*100:.2f}\")\n\n\n#     if val_hd < best_hd and val_hd > 0:\n\n#         best_hd = val_hd\n#         best_hd_epoch = epoch\n\n#     if wandb_log:\n#         wandb.log({\"Test Dice\" : val_dice * 100,\n#                    \"Test Best Dice\" : best_dice * 100,\n#                    \"Test Hausdorff Distance\" : hd_metric.aggregate().item(),\n#                    \"Test Best HD\" : best_hd,\n#                    \"Epoch\" : epoch })\n\n#         preds = torch.stack([argmax(c) for c in preds])\n#         labels = torch.stack([argmax(c) for c in labels])\n\n\n#         f = make_grid(torch.cat([imgs,labels,preds],dim=3), nrow =2, padding = 20, pad_value = 1)\n#         images = wandb.Image(rearrange(f.cpu(), 'c h w -> h w c'), caption=\"Left: Input, Middle : Ground Truth, Right: Prediction\")\n#         wandb.log({\"Predictions\": images, \"Epoch\" : epoch})\n#         print('Logged data to wandb')\n\n#     dice_metric.reset()\n#     hd_metric.reset()\n\n# # ---------------------------------------------------------------------\n\n# print(f\"Completed training, best model saved at epoch {best_dice_epoch} with Dice {best_dice*100:.2f} and Best HD {best_hd:.2f} at epoch {best_hd_epoch}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-20T19:21:38.825237Z","iopub.execute_input":"2022-08-20T19:21:38.825970Z"},"trusted":true},"execution_count":null,"outputs":[]}]}